{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s): Ojas Patel, Pranav Naravetla, Suhas Dara, Avinash Damania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKCupid Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will use an OKCupid dataset to solve the problem of predicting ___ using information from dating profiles such as physical traits and lifestyle choices.\n",
    "\n",
    "\n",
    "(What is the data science problem you are trying to solve? Why does the problem matter? What could the results of your predictive model be used for? Why would we want to be able to predict the thing you’re trying to predict? Then describe the dataset that you will use to tackle this problem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some headers\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import rand\n",
    "from numpy import square, sqrt\n",
    "from pandas import DataFrame\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "In this section, we will clean the data in preparation for use in training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>i'm looking to meet someone who i have a lot i...</td>\n",
       "      <td>i work in the tech industry during the day, an...</td>\n",
       "      <td>i'm an expert at scrabble, designing ambigrams...</td>\n",
       "      <td>my lip ring, which i use to distract people fr...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and has cats</td>\n",
       "      <td>christianity and laughing about it</td>\n",
       "      <td>m</td>\n",
       "      <td>taurus but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), chinese (fluently), japane...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>they say i'm a smart, funny, worldly girl who ...</td>\n",
       "      <td>i'm transitioning from a lost, once ambitious ...</td>\n",
       "      <td>listening&lt;br /&gt;\\n&lt;br /&gt;\\nnot judging others&lt;br...</td>\n",
       "      <td>eyes&lt;br /&gt;\\n&lt;br /&gt;\\nsmile&lt;br /&gt;\\n&lt;br /&gt;\\nthoug...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>aries and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>update: i am in bmore/philly till may 27th for...</td>\n",
       "      <td>i'm self-employed events technician and it's w...</td>\n",
       "      <td>being a smart ass, saying inappropriate things...</td>\n",
       "      <td>my charming good looks and the piece of lettuc...</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), swedish (okay), spanish (p...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gay</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>other</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english, spanish (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hmmi freely give compliments. i appreciate a g...</td>\n",
       "      <td>i'm a teacher by day and i usually love it. i'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>taurus and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age body_type             diet      drinks      drugs  \\\n",
       "0           0   28  athletic  mostly anything    socially  sometimes   \n",
       "1           1   34   average  mostly anything    socially      never   \n",
       "2           2   29       fit  mostly anything    socially      never   \n",
       "3           3   45  athletic              NaN  not at all      never   \n",
       "4           4   37   average              NaN    socially        NaN   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  i'm looking to meet someone who i have a lot i...   \n",
       "1  they say i'm a smart, funny, worldly girl who ...   \n",
       "2  update: i am in bmore/philly till may 27th for...   \n",
       "3                                                NaN   \n",
       "4  hmmi freely give compliments. i appreciate a g...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  i work in the tech industry during the day, an...   \n",
       "1  i'm transitioning from a lost, once ambitious ...   \n",
       "2  i'm self-employed events technician and it's w...   \n",
       "3                                                NaN   \n",
       "4  i'm a teacher by day and i usually love it. i'...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  i'm an expert at scrabble, designing ambigrams...   \n",
       "1  listening<br />\\n<br />\\nnot judging others<br...   \n",
       "2  being a smart ass, saying inappropriate things...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  my lip ring, which i use to distract people fr...  ...   \n",
       "1  eyes<br />\\n<br />\\nsmile<br />\\n<br />\\nthoug...  ...   \n",
       "2  my charming good looks and the piece of lettuc...  ...   \n",
       "3                                                NaN  ...   \n",
       "4                                                NaN  ...   \n",
       "\n",
       "                    location offspring orientation                       pets  \\\n",
       "0  san francisco, california       NaN    straight    likes dogs and has cats   \n",
       "1  san francisco, california       NaN    straight    has dogs and likes cats   \n",
       "2        oakland, california       NaN    straight  likes dogs and likes cats   \n",
       "3  san francisco, california       NaN         gay  likes dogs and likes cats   \n",
       "4  san francisco, california       NaN    straight                        NaN   \n",
       "\n",
       "                             religion sex  \\\n",
       "0  christianity and laughing about it   m   \n",
       "1                                 NaN   f   \n",
       "2                                 NaN   m   \n",
       "3                               other   m   \n",
       "4                                 NaN   f   \n",
       "\n",
       "                                       sign  smokes  \\\n",
       "0        taurus but it doesn&rsquo;t matter      no   \n",
       "1   aries and it&rsquo;s fun to think about      no   \n",
       "2                                       NaN      no   \n",
       "3                                    cancer      no   \n",
       "4  taurus and it&rsquo;s fun to think about      no   \n",
       "\n",
       "                                              speaks  status  \n",
       "0  english (fluently), chinese (fluently), japane...  single  \n",
       "1                                            english  single  \n",
       "2  english (fluently), swedish (okay), spanish (p...  single  \n",
       "3                          english, spanish (poorly)  single  \n",
       "4                                            english  single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_profiles.csv\")\n",
    "df.columns\n",
    "\n",
    "# we must drop rows that do not have an education value to deal with missing values\n",
    "df = df[df.education.notnull()]\n",
    "\n",
    "label = df['education']\n",
    "data = df.drop(columns=['education'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     1782\n",
       "age            1782\n",
       "body_type      1635\n",
       "diet           1082\n",
       "drinks         1727\n",
       "drugs          1392\n",
       "essay0         1615\n",
       "essay1         1572\n",
       "essay2         1530\n",
       "essay3         1469\n",
       "essay4         1509\n",
       "essay5         1497\n",
       "essay6         1429\n",
       "essay7         1451\n",
       "essay8         1235\n",
       "essay9         1453\n",
       "ethnicity      1627\n",
       "height         1782\n",
       "income         1782\n",
       "job            1609\n",
       "last_online    1782\n",
       "location       1782\n",
       "offspring       757\n",
       "orientation    1782\n",
       "pets           1230\n",
       "religion       1243\n",
       "sex            1782\n",
       "sign           1511\n",
       "smokes         1645\n",
       "speaks         1780\n",
       "status         1782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Unnamed: 0', 'essay0', 'essay1','essay2','essay3','essay4','essay5','essay6','essay7'\n",
    "                  ,'essay8','essay9','last_online','sign','offspring', 'diet', 'speaks','location','status', 'income'],axis=0)\n",
    "\n",
    "# removing Unnamed: 0 as it is a repeat of the index\n",
    "\n",
    "# removing essay0, essay1, essay2, essay3, essay4, essay5, essay6, essay7, essay8, essay9 as every row has \n",
    "#a unique value\n",
    "\n",
    "# removing last_online as it can't be used to predict the label (education)\n",
    "\n",
    "# removing sign as it can't be used to predict the label (education)\n",
    "\n",
    "# removing offspring as too many rows have NaN as a value\n",
    "\n",
    "# removing diet as too many rows have NaN as a value\n",
    "\n",
    "# removing speaks as there are too many distinct values and cannot be mapped into a smaller domain\n",
    "\n",
    "# removing location as there art too many distinct values and it cannot be used to predict the label (educatin)\n",
    "\n",
    "# removing status as there is a heavy imbalance with almost all of the values being 'single'\n",
    "\n",
    "# removing income as almost all values are not listed (value put as -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_engineering = {\n",
    "    'graduated from college/university': 'bachelors',\n",
    "    'greatued from masters program': 'advanced degree',\n",
    "    'working on college/university': 'bachelors',\n",
    "    'working on masters program': 'advanced degree',\n",
    "    'graduated from two-year college': 'associates',\n",
    "    'graduated from high school': 'high-school',\n",
    "    'graduated from ph.d program': 'advanced degree',\n",
    "    'graduated from law school': 'advanced degree',\n",
    "    'working on two-year college': 'associates',\n",
    "    'working on ph.d program': 'advanced degree',\n",
    "    'dropped out of college/university': 'high-school',\n",
    "    'college/university': 'bachelors',\n",
    "    'graduated from space camp': 'spacecamp',\n",
    "    'dropped out of space camp': 'spacecamp',\n",
    "    'graduated from med school': 'advanced degree',\n",
    "    'working on space camp': 'spacecamp',\n",
    "    'working on law school': 'advanced degree',\n",
    "    'working on med school': 'advanced degree',\n",
    "    'dropped out of two-year college': 'high-school',\n",
    "    'two-year college': 'associates',\n",
    "    'masters program': 'advanced degree',\n",
    "    'dropped out of masters program': 'advanced degree',\n",
    "    'dropped out of ph.d program': 'advanced degree',\n",
    "    'high school': 'high-school',\n",
    "    'dropped out of high school': 'high-school',\n",
    "    'working on high school': 'high-school',\n",
    "    'space camp': 'spacecamp',\n",
    "    'ph.d program': 'advanced degree',\n",
    "    'med school': 'advanced degree',\n",
    "    'law school': 'advanced degree',\n",
    "    'dropped out of law school': 'advanced degree',\n",
    "    'dropped out of med school': 'advanced degree',\n",
    "    'graduated from masters program': 'advanced degree'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.replace(label_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bachelors          1059\n",
       "advanced degree     501\n",
       "associates           84\n",
       "high-school          77\n",
       "spacecamp            61\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            1782\n",
       "body_type      1635\n",
       "drinks         1727\n",
       "drugs          1392\n",
       "ethnicity      1627\n",
       "height         1782\n",
       "job            1609\n",
       "orientation    1782\n",
       "pets           1230\n",
       "religion       1243\n",
       "sex            1782\n",
       "smokes         1645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we must fill in missing values for remaining columns\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average           428\n",
       "fit               377\n",
       "athletic          367\n",
       "thin              147\n",
       "curvy             115\n",
       "a little extra     73\n",
       "skinny             51\n",
       "full figured       38\n",
       "jacked             16\n",
       "overweight         13\n",
       "used up             6\n",
       "rather not say      4\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age, sex, orientation are completely full\n",
    "# First we will check unique values for body_type and fill in missing values\n",
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "athletic       760\n",
       "average        579\n",
       "overweight     245\n",
       "underweight    198\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About 6% of the elements are missing a value for body_type. Given that 'average' is the mode of all the values \n",
    "# and that it is safe to assume that the typical person have an 'average' body_type, we will fill the NaNs \n",
    "# with 'average'\n",
    "\n",
    "body_type_dictionary = {\n",
    "    'average': 'average',\n",
    "    'athletic': 'athletic',\n",
    "    'fit': 'athletic',\n",
    "    'thin': 'underweight',\n",
    "    'curvy': 'overweight',\n",
    "    'a little extra': 'overweight',\n",
    "    'skinny': 'underweight',\n",
    "    'full figured': 'overweight',\n",
    "    'jacked': 'athletic',\n",
    "    'overweight': 'overweight',\n",
    "    'used up': 'overweight',\n",
    "    'rather not say': 'average'\n",
    "}\n",
    "\n",
    "data['body_type'] = data['body_type'].fillna('average')\n",
    "data['body_type'] = data['body_type'].replace(body_type_dictionary)\n",
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "socially       1239\n",
       "rarely          194\n",
       "often           176\n",
       "not at all       90\n",
       "desperately      15\n",
       "very often       13\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for drinks and fill in missing values\n",
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sometimes     1294\n",
       "rarely         194\n",
       "often          176\n",
       "never           90\n",
       "very often      28\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as the values are categorical, the mode is 'socially' and makes up about 70% of the total data, so we will fill all \n",
    "# NaNs with 'socially'\n",
    "\n",
    "# Narrowed down the categories to sometimes, often, and rarely because some of them were redundant\n",
    "\n",
    "drinks_dictionary = {\n",
    "    'socially': 'sometimes',\n",
    "    'often': 'often',\n",
    "    'rarely': 'rarely',\n",
    "    'not at all': 'never',\n",
    "    'desperately': 'very often',\n",
    "    'very often': 'very often'\n",
    "}\n",
    "\n",
    "data['drinks'] = data['drinks'].fillna('socially')\n",
    "data['drinks'] = data['drinks'].replace(drinks_dictionary)\n",
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        1134\n",
       "sometimes     240\n",
       "often          18\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for drugs and fill in missing values\n",
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        1524\n",
       "sometimes     240\n",
       "often          18\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as the values are categorical, the mode is 'never; and it makes up for about 80% of values with a value for 'drugs'\n",
    "data['drugs'] = data['drugs'].fillna('never')\n",
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                                                                                                      1013\n",
       "asian                                                                                                       163\n",
       "hispanic / latin                                                                                             69\n",
       "black                                                                                                        61\n",
       "other                                                                                                        48\n",
       "hispanic / latin, white                                                                                      42\n",
       "indian                                                                                                       38\n",
       "asian, white                                                                                                 26\n",
       "white, other                                                                                                 21\n",
       "asian, pacific islander                                                                                      14\n",
       "middle eastern                                                                                               13\n",
       "black, white                                                                                                 11\n",
       "native american, white                                                                                       10\n",
       "black, other                                                                                                 10\n",
       "middle eastern, white                                                                                         9\n",
       "hispanic / latin, other                                                                                       8\n",
       "black, native american, white                                                                                 7\n",
       "pacific islander                                                                                              6\n",
       "asian, other                                                                                                  5\n",
       "native american                                                                                               4\n",
       "hispanic / latin, white, other                                                                                4\n",
       "middle eastern, hispanic / latin                                                                              4\n",
       "pacific islander, white                                                                                       4\n",
       "black, hispanic / latin                                                                                       3\n",
       "black, white, other                                                                                           2\n",
       "asian, pacific islander, hispanic / latin, white, other                                                       2\n",
       "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other       2\n",
       "asian, white, other                                                                                           2\n",
       "black, hispanic / latin, white                                                                                2\n",
       "asian, pacific islander, white                                                                                2\n",
       "middle eastern, indian, other                                                                                 1\n",
       "native american, other                                                                                        1\n",
       "middle eastern, other                                                                                         1\n",
       "black, native american, white, other                                                                          1\n",
       "pacific islander, hispanic / latin, white                                                                     1\n",
       "native american, pacific islander, hispanic / latin, white, other                                             1\n",
       "indian, other                                                                                                 1\n",
       "native american, pacific islander                                                                             1\n",
       "asian, hispanic / latin, white                                                                                1\n",
       "asian, middle eastern, black, indian, pacific islander, hispanic / latin, white                               1\n",
       "native american, white, other                                                                                 1\n",
       "asian, hispanic / latin                                                                                       1\n",
       "asian, pacific islander, hispanic / latin                                                                     1\n",
       "indian, white, other                                                                                          1\n",
       "asian, black, pacific islander, hispanic / latin, white                                                       1\n",
       "asian, native american, white, other                                                                          1\n",
       "asian, black                                                                                                  1\n",
       "pacific islander, white, other                                                                                1\n",
       "black, indian, white, other                                                                                   1\n",
       "native american, hispanic / latin                                                                             1\n",
       "indian, hispanic / latin                                                                                      1\n",
       "pacific islander, other                                                                                       1\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for ethnicity and fill in missing values\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white       1189\n",
       "asian        221\n",
       "mixed        164\n",
       "hispanic      77\n",
       "black         71\n",
       "other         48\n",
       "pacific        7\n",
       "native         5\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as the values are categorical, the mode is 'white' and makes up about 50% of the total data, so we will fill \n",
    "# all NaNs with 'white'\n",
    "\n",
    "# Narrowed down the categories to white, asian, black, hispanic, native, pacific, mixed, and other \n",
    "# because of a lot of diversity. If only second ethnicity is 'other', it might be insignificant enough to be\n",
    "# ignored, and is classified as the first ethnicity\n",
    "\n",
    "ethnicity_dictionary = {\n",
    "    'white': 'white',\n",
    "    'asian': 'asian',\n",
    "    'hispanic / latin': 'hispanic',\n",
    "    'black': 'black',\n",
    "    'other': 'other',\n",
    "    'hispanic / latin, white': 'mixed',\n",
    "    'indian': 'asian',\n",
    "    'asian, white': 'mixed',\n",
    "    'white, other': 'white',\n",
    "    'asian, pacific islander': 'mixed',\n",
    "    'middle eastern': 'asian',\n",
    "    'black, white': 'mixed',\n",
    "    'native american, white': 'mixed',\n",
    "    'black, other': 'black',\n",
    "    'middle eastern, white': 'mixed',\n",
    "    'hispanic / latin, other': 'hispanic',\n",
    "    'black, native american, white': 'mixed',\n",
    "    'pacific islander': 'pacific',\n",
    "    'asian, other': 'asian',\n",
    "    'pacific islander, white': 'mixed',\n",
    "    'native american': 'native',\n",
    "    'middle eastern, hispanic / latin': 'mixed',\n",
    "    'hispanic / latin, white, other': 'mixed',\n",
    "    'black, hispanic / latin': 'mixed',\n",
    "    'asian, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'black, hispanic / latin, white': 'mixed',\n",
    "    'asian, white, other': 'mixed',\n",
    "    'asian, pacific islander, white': 'mixed',\n",
    "    'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'black, white, other': 'mixed',\n",
    "    'indian, other': 'asian',\n",
    "    'indian, white, other': 'mixed',\n",
    "    'black, indian, white, other': 'mixed',\n",
    "    'native american, other': 'native',\n",
    "    'asian, native american, white, other': 'mixed',\n",
    "    'native american, white, other': 'mixed',\n",
    "    'asian, hispanic / latin': 'mixed',\n",
    "    'asian, hispanic / latin, white': 'mixed',\n",
    "    'native american, hispanic / latin': 'mixed',\n",
    "    'native american, pacific islander': 'mixed',\n",
    "    'pacific islander, white, other': 'mixed',\n",
    "    'middle eastern, indian, other': 'mixed',\n",
    "    'pacific islander, other': 'pacific',\n",
    "    'middle eastern, other': 'asian',\n",
    "    'asian, pacific islander, hispanic / latin': 'mixed',\n",
    "    'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'asian, black, pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'black, native american, white, other': 'mixed',\n",
    "    'native american, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'indian, hispanic / latin': 'mixed',\n",
    "    'asian, black': 'mixed'\n",
    "}\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].fillna('white')\n",
    "data['ethnicity'] = data['ethnicity'].replace(ethnicity_dictionary)\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will fill missing values in height with the mean height of their respective genders\n",
    "data['height'] = df['height'].fillna(df.groupby('sex')['height'].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                217\n",
       "student                              159\n",
       "science / tech / engineering         158\n",
       "computer / hardware / software       153\n",
       "artistic / musical / writer          136\n",
       "sales / marketing / biz dev          127\n",
       "education / academia                 117\n",
       "medicine / health                     93\n",
       "entertainment / media                 89\n",
       "banking / financial / real estate     80\n",
       "executive / management                67\n",
       "hospitality / travel                  40\n",
       "law / legal services                  35\n",
       "clerical / administrative             31\n",
       "political / government                27\n",
       "construction / craftsmanship          26\n",
       "rather not say                        14\n",
       "transportation                        14\n",
       "unemployed                            10\n",
       "retired                                9\n",
       "military                               7\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for jobs and fill in missing values\n",
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STEM           444\n",
       "other          404\n",
       "business       345\n",
       "arts           287\n",
       "student        159\n",
       "education      117\n",
       "not working     19\n",
       "military         7\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as the values are categorical, and quite a few people already did not want to reveal their job anyways,\n",
    "# the empty fields are also clumped into the 'rather not say' category\n",
    "\n",
    "# Narrowed down the categories to student, STEM, arts, business, education, military, not working, military \n",
    "# because of a lot of different jobs.\n",
    "\n",
    "job_dictionary = {\n",
    "    'other': 'other',\n",
    "    'student': 'student',\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    'artistic / musical / writer': 'arts',\n",
    "    'sales / marketing / biz dev': 'business',\n",
    "    'education / academia': 'education',\n",
    "    'medicine / health': 'STEM',\n",
    "    'banking / financial / real estate': 'business',\n",
    "    'executive / management': 'business',\n",
    "    'hospitality / travel': 'business',\n",
    "    'entertainment / media': 'arts',\n",
    "    'law / legal services': 'arts',\n",
    "    'clerical / administrative': 'business',\n",
    "    'political / government': 'arts', \n",
    "    'construction / craftsmanship': 'STEM',\n",
    "    'rather not say': 'other',\n",
    "    'transportation': 'STEM',\n",
    "    'unemployed': 'not working',\n",
    "    'retired': 'not working',\n",
    "    'military': 'military'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].fillna('rather not say')\n",
    "data['job'] = data['job'].replace(job_dictionary)\n",
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes dogs and likes cats          455\n",
       "likes dogs                         190\n",
       "likes dogs and has cats            155\n",
       "has dogs                           137\n",
       "has dogs and likes cats             80\n",
       "likes dogs and dislikes cats        63\n",
       "has cats                            49\n",
       "has dogs and has cats               47\n",
       "likes cats                          27\n",
       "dislikes dogs and dislikes cats     10\n",
       "has dogs and dislikes cats           9\n",
       "dislikes dogs and likes cats         4\n",
       "dislikes cats                        3\n",
       "dislikes dogs and has cats           1\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for pets and fill in missing values\n",
    "# maybe we should remove because there are a lot of missing values\n",
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes       1291\n",
       "owns         478\n",
       "dislikes      13\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrowed down the categories to owns, likes, or dislikes pets.\n",
    "\n",
    "pet_dictionary = {\n",
    "    'likes dogs and likes cats': 'likes',\n",
    "    'likes dogs': 'likes',\n",
    "    'likes dogs and has cats': 'owns',\n",
    "    'has dogs': 'owns',\n",
    "    'has dogs and likes cats': 'owns',\n",
    "    'likes dogs and dislikes cats': 'likes',\n",
    "    'has cats': 'owns',\n",
    "    'has dogs and has cats': 'owns',\n",
    "    'likes cats': 'likes',\n",
    "    'dislikes dogs and dislikes cats': 'dislikes',\n",
    "    'has dogs and dislikes cats': 'owns',\n",
    "    'dislikes dogs and likes cats': 'likes',\n",
    "    'dislikes cats': 'dislikes',\n",
    "    'dislikes dogs and has cats': 'owns'\n",
    "}\n",
    "\n",
    "# will fill NaNs with 'likes' as the average person does not mind pets, but we do not want to assume ownership\n",
    "data['pets'] = data['pets'].fillna('likes')\n",
    "data['pets'] = data['pets'].replace(pet_dictionary)\n",
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agnosticism but not too serious about it      97\n",
       "agnosticism                                   86\n",
       "agnosticism and laughing about it             80\n",
       "other                                         77\n",
       "atheism                                       65\n",
       "other and laughing about it                   63\n",
       "christianity                                  62\n",
       "catholicism but not too serious about it      62\n",
       "atheism and laughing about it                 58\n",
       "christianity but not too serious about it     56\n",
       "atheism but not too serious about it          50\n",
       "other but not too serious about it            47\n",
       "judaism but not too serious about it          45\n",
       "catholicism                                   38\n",
       "other and somewhat serious about it           30\n",
       "catholicism and laughing about it             29\n",
       "atheism and somewhat serious about it         26\n",
       "christianity and somewhat serious about it    26\n",
       "buddhism and laughing about it                23\n",
       "agnosticism and somewhat serious about it     21\n",
       "judaism and laughing about it                 19\n",
       "judaism                                       18\n",
       "atheism and very serious about it             17\n",
       "catholicism and somewhat serious about it     16\n",
       "buddhism but not too serious about it         16\n",
       "buddhism                                      15\n",
       "christianity and very serious about it        15\n",
       "other and very serious about it               14\n",
       "christianity and laughing about it            13\n",
       "agnosticism and very serious about it         12\n",
       "buddhism and somewhat serious about it         8\n",
       "hinduism but not too serious about it          7\n",
       "judaism and somewhat serious about it          6\n",
       "catholicism and very serious about it          6\n",
       "buddhism and very serious about it             4\n",
       "hinduism and somewhat serious about it         4\n",
       "hinduism                                       3\n",
       "islam                                          3\n",
       "islam and very serious about it                2\n",
       "islam but not too serious about it             2\n",
       "hinduism and laughing about it                 1\n",
       "islam and somewhat serious about it            1\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for religion and fill in missing values\n",
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not-listed    770\n",
       "christian     323\n",
       "agnostic      296\n",
       "atheist       216\n",
       "jewish         88\n",
       "buddhist       66\n",
       "hindu          15\n",
       "muslim          8\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_dictionary = {    \n",
    "    \"agnosticism but not too serious about it\": \"agnostic\",\n",
    "    \"agnosticism\": \"agnostic\",\n",
    "    \"agnosticism and laughing about it\": \"agnostic\",\n",
    "    \"other\": \"not-listed\",\n",
    "    \"atheism\": \"atheist\",\n",
    "    \"other and laughing about it\": \"not-listed\",\n",
    "    \"christianity\": \"christian\",\n",
    "    \"catholicism but not too serious about it\": \"christian\",\n",
    "    \"atheism and laughing about it\": \"atheist\",\n",
    "    \"christianity but not too serious about it\": \"christian\",\n",
    "    \"atheism but not too serious about it\": \"atheist\",\n",
    "    \"other but not too serious about it\": \"not-listed\",\n",
    "    \"judaism but not too serious about it\": \"jewish\",\n",
    "    \"catholicism\": \"christian\",\n",
    "    \"other and somewhat serious about it\": \"not-listed\",\n",
    "    \"catholicism and laughing about it\": \"christian\",\n",
    "    \"christianity and somewhat serious about it\": \"christian\",\n",
    "    \"atheism and somewhat serious about it\": \"atheist\",\n",
    "    \"buddhism and laughing about it\": \"buddhist\",\n",
    "    \"agnosticism and somewhat serious about it\": \"agnostic\",\n",
    "    \"judaism and laughing about it\": \"jewish\",\n",
    "    \"judaism\": \"jewish\",\n",
    "    \"atheism and very serious about it\": \"atheist\",\n",
    "    \"catholicism and somewhat serious about it\": \"christian\",\n",
    "    \"buddhism but not too serious about it\": \"buddhist\",\n",
    "    \"buddhism\": \"buddhist\",\n",
    "    \"christianity and very serious about it\": \"christian\",\n",
    "    \"other and very serious about it\": \"not-listed\",\n",
    "    \"christianity and laughing about it\": \"christian\",\n",
    "    \"agnosticism and very serious about it\": \"agnostic\",\n",
    "    \"buddhism and somewhat serious about it\": \"buddhist\",\n",
    "    \"hinduism but not too serious about it\": \"hindu\",\n",
    "    \"judaism and somewhat serious about it\": \"jewish\",\n",
    "    \"catholicism and very serious about it\": \"christian\",\n",
    "    \"hinduism and somewhat serious about it\": \"hindu\",\n",
    "    \"buddhism and very serious about it\": \"buddhist\",\n",
    "    \"hinduism\": \"hindu\",\n",
    "    \"islam\": \"muslim\",\n",
    "    \"islam but not too serious about it\": \"muslim\",\n",
    "    \"islam and very serious about it\": \"muslim\",\n",
    "    \"hinduism and laughing about it\": \"hindu\",\n",
    "    \"islam and somewhat serious about it\": \"muslim\",\n",
    "    \"hinduism and very serious about it\": \"hindu\",\n",
    "    \"judaism and very serious about it\": \"jewish\",\n",
    "    \"islam and laughing about it\": \"muslim\"\n",
    "}\n",
    "\n",
    "data['religion'] = data['religion'].fillna('not-listed')\n",
    "data['religion'] = data['religion'].replace(religion_dictionary)\n",
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                1352\n",
       "sometimes          110\n",
       "when drinking       83\n",
       "yes                 55\n",
       "trying to quit      45\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for smokes and fill in missing values\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                1489\n",
       "sometimes          110\n",
       "when drinking       83\n",
       "yes                 55\n",
       "trying to quit      45\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'no' is the mode and makes up about 75% of the data, so we will fill NaNs with 'no'\n",
    "data['smokes'] = data['smokes'].fillna('no')\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNo need to deal with noise/outliers as there are no chances of noise in the data collection as it is\\nall user entered. Additionally, as the data is mainly categorical, it is tough to determine something \\nas an outlier as it can't be plotted in an n-dimensional plot.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "No need to deal with noise/outliers as there are no chances of noise in the data collection as it is\n",
    "all user entered. Additionally, as the data is mainly categorical, it is tough to determine something \n",
    "as an outlier as it can't be plotted in an n-dimensional plot.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>job</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>athletic</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>asian</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>STEM</td>\n",
       "      <td>straight</td>\n",
       "      <td>owns</td>\n",
       "      <td>christian</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>average</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "      <td>owns</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22</td>\n",
       "      <td>athletic</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>arts</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.54</td>\n",
       "      <td>athletic</td>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>education</td>\n",
       "      <td>gay</td>\n",
       "      <td>likes</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.38</td>\n",
       "      <td>average</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>never</td>\n",
       "      <td>white</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>education</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age body_type     drinks      drugs ethnicity    height        job  \\\n",
       "0  0.20  athletic  sometimes  sometimes     asian  0.210526       STEM   \n",
       "1  0.32   average  sometimes      never     white  0.157895      other   \n",
       "2  0.22  athletic  sometimes      never     white  0.342105       arts   \n",
       "3  0.54  athletic      never      never     mixed  0.289474  education   \n",
       "4  0.38   average  sometimes      never     white  0.157895  education   \n",
       "\n",
       "  orientation   pets    religion sex smokes  \n",
       "0    straight   owns   christian   m     no  \n",
       "1    straight   owns  not-listed   f     no  \n",
       "2    straight  likes  not-listed   m     no  \n",
       "3         gay  likes  not-listed   m     no  \n",
       "4    straight  likes  not-listed   f     no  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can normalize the age and height\n",
    "\n",
    "# normalize age\n",
    "max_age = max(data['age'])\n",
    "min_age = min(data['age'])\n",
    "data['age'] = (data['age'] - min_age) / (max_age - min_age)\n",
    "\n",
    "# normalize height\n",
    "max_height = max(data['height'])\n",
    "min_height = min(data['height'])\n",
    "data['height'] = (data['height'] - min_height) / (max_height - min_height)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  body_type  drinks  drugs ethnicity    height        job  \\\n",
      "0     0.20          2       2      1     asian  0.210526       STEM   \n",
      "1     0.32          1       2      0     white  0.157895      other   \n",
      "2     0.22          2       2      0     white  0.342105       arts   \n",
      "3     0.54          2       0      0     mixed  0.289474  education   \n",
      "4     0.38          1       2      0     white  0.157895  education   \n",
      "...    ...        ...     ...    ...       ...       ...        ...   \n",
      "1972  0.04          0       2      0     white  0.315789    student   \n",
      "1973  0.30          2       2      0     white  0.394737   business   \n",
      "1974  0.56          1       2      0     white  0.394737       STEM   \n",
      "1975  0.46          2       1      0   pacific  0.263158       arts   \n",
      "1976  0.52          3       2      1     white  0.263158      other   \n",
      "\n",
      "     orientation   pets    religion  sex  smokes  \n",
      "0       straight   owns   christian    0       0  \n",
      "1       straight   owns  not-listed    1       0  \n",
      "2       straight  likes  not-listed    0       0  \n",
      "3            gay  likes  not-listed    0       0  \n",
      "4       straight  likes  not-listed    1       0  \n",
      "...          ...    ...         ...  ...     ...  \n",
      "1972    straight  likes  not-listed    0       0  \n",
      "1973    straight  likes     atheist    0       0  \n",
      "1974    straight   owns    agnostic    0       0  \n",
      "1975    straight  likes    buddhist    0       0  \n",
      "1976    straight  likes  not-listed    1       0  \n",
      "\n",
      "[1782 rows x 12 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-efaad7b2d858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drugs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrugs_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drinks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drinks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrinks_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_type_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4176\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m         )\n\u001b[1;32m   4180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6645\u001b[0m             return self.replace(\n\u001b[0;32m-> 6646\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6647\u001b[0m             )\n\u001b[1;32m   6648\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4176\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m         )\n\u001b[1;32m   4180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6697\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6698\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6699\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6700\u001b[0m                     )\n\u001b[1;32m   6701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, regex)\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1936\u001b[0;31m             \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1937\u001b[0m         )\n\u001b[1;32m   1938\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "print(data)\n",
    "drugs_codes = {\n",
    "    'never': 0,\n",
    "    'sometimes': 1,\n",
    "    'often': 2\n",
    "}\n",
    "\n",
    "drinks_codes = {\n",
    "    'never': 0,\n",
    "    'rarely': 1,\n",
    "    'sometimes': 2,\n",
    "    'often': 3,\n",
    "    'very often': 4\n",
    "}\n",
    "\n",
    "body_type_codes = {\n",
    "    'underweight': 0,\n",
    "    'average': 1,\n",
    "    'athletic': 2,\n",
    "    'overweight': 3,\n",
    "}\n",
    "\n",
    "smokes_codes = {\n",
    "    \"no\": 0,\n",
    "    \"when drinking\": 1,\n",
    "    \"trying to quit\": 2,\n",
    "    \"sometimes\": 3,\n",
    "    \"yes\": 4\n",
    "}\n",
    "\n",
    "sex_codes = {\n",
    "    \"m\": 0,\n",
    "    \"f\": 1\n",
    "}\n",
    "\n",
    "# religion_codes = {\n",
    "#     \"not-listed\": \n",
    "#     \"christian\":     \n",
    "#     \"agnostic\":      \n",
    "#     \"atheist\":       \n",
    "#     \"jewish\": \n",
    "#     \"buddhist\":\n",
    "#     \"hindu\":          \n",
    "#     \"muslim\":  \n",
    "# }\n",
    "\n",
    "data['drugs'] = data['drugs'].replace(drugs_codes)\n",
    "data['drinks'] = data['drinks'].replace(drinks_codes)\n",
    "data['body_type'] = data['body_type'].replace(body_type_codes)\n",
    "data['smokes'] = data['smokes'].replace(smokes_codes)\n",
    "data['sex'] = data['sex'].replace(sex_codes)\n",
    "print(data)\n",
    "print(label)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline = Pipeline(steps=[('PCA', pca), ('KNN', knn)])\n",
    "\n",
    "scores = cross_val_score(pipeline, data.drop(columns = ['ethnicity', 'job', \n",
    "                                                'orientation', 'pets', 'religion']), label, cv=5)\n",
    "print(\"Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
