{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name(s):\n",
    "- Ojas Patel (ovp74)\n",
    "- Pranav Neravetla (prn289)\n",
    "- Suhas Dara (sd35633)\n",
    "- Avinash Damania (ad44428)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKCupid Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will use an OKCupid dataset to solve the problem of predicting education level using information from dating profiles such as physical traits and lifestyle choices. Predicting someone's education level from their dating profile is useful for those with dating preferences. When making a profile, people will often avoid filling out certain fields, meaning that someone could match most of your preferences but be at a different stage of their education or career. For those who would prefer dating someone they can more strongly relate to in terms of school/work, predicting their education level can be quite valuable.\n",
    "\n",
    "The OKCupid dataset we will use contains 19782 profiles from various residents of California. These profiles each have several different attributes that describe the person, such as age, body type, diet, and more. These attributes will be the basis of our predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Some headers\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing, decomposition, neighbors, pipeline, tree, svm, multiclass\n",
    "from sklearn import naive_bayes, neural_network, ensemble, metrics, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Exploration\n",
    "\n",
    "In this section, we will clean and engineer the data in preparation for use in training our models. Some of the tasks necessary include dropping unusable attributes, checking for missing values, feature engineering, removing outliers, and looking for potential class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "\n",
    "For the sake of efficiency while developing our models, we used a downsampled data set from test_profiles.csv. Our\n",
    "\n",
    "In the event that a row does not have a value for education, we must drop it, since we need labeled data for training testing. Otherwise, we form our data and label sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm tall and slender, have a good creative job...</td>\n",
       "      <td>i'm trying to balance my innate sense of respo...</td>\n",
       "      <td>sending funny text messages. speling (of cours...</td>\n",
       "      <td>i'm usually smiling. and as noted, i'm fairly ...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, and doesn&amp;rsquo;t wan...</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and has cats</td>\n",
       "      <td>atheism and laughing about it</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>often</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my job? thinking about dinner when i should re...</td>\n",
       "      <td>awkward as hell.</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>atheism and laughing about it</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>seeing someone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>skinny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>very easy going:) love to read, photography is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>conversation, photography, writing, cooking, s...</td>\n",
       "      <td>my glasses:)</td>\n",
       "      <td>...</td>\n",
       "      <td>alameda, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>gay</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>judaism but not too serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>sagittarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am always wanting to try new things--new act...</td>\n",
       "      <td>i about to graduate from cal as psych major an...</td>\n",
       "      <td>picking up new activities to try out and learn...</td>\n",
       "      <td>my smile! my friends say i seem happy about ev...</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english (fluently), chinese (okay)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>i work out somewhat regularly, dark hair and e...</td>\n",
       "      <td>i am gainfully employed and work as a project ...</td>\n",
       "      <td>i am good at making people laugh and feel comf...</td>\n",
       "      <td>blunt, unapologetic honesty. i don't understan...</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs and likes cats</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age body_type             diet    drinks  drugs  \\\n",
       "0           0   47       fit  mostly anything     often    NaN   \n",
       "1           1   27       NaN              NaN     often  never   \n",
       "2           2   43    skinny              NaN  socially  never   \n",
       "3           3   22       NaN  mostly anything       NaN    NaN   \n",
       "4           4   31       fit  mostly anything  socially  never   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  i'm tall and slender, have a good creative job...   \n",
       "1                                                NaN   \n",
       "2  very easy going:) love to read, photography is...   \n",
       "3  i am always wanting to try new things--new act...   \n",
       "4  i work out somewhat regularly, dark hair and e...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  i'm trying to balance my innate sense of respo...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  i about to graduate from cal as psych major an...   \n",
       "4  i am gainfully employed and work as a project ...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  sending funny text messages. speling (of cours...   \n",
       "1  my job? thinking about dinner when i should re...   \n",
       "2  conversation, photography, writing, cooking, s...   \n",
       "3  picking up new activities to try out and learn...   \n",
       "4  i am good at making people laugh and feel comf...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  i'm usually smiling. and as noted, i'm fairly ...  ...   \n",
       "1                                   awkward as hell.  ...   \n",
       "2                                       my glasses:)  ...   \n",
       "3  my smile! my friends say i seem happy about ev...  ...   \n",
       "4  blunt, unapologetic honesty. i don't understan...  ...   \n",
       "\n",
       "                    location  \\\n",
       "0  san francisco, california   \n",
       "1  san francisco, california   \n",
       "2        alameda, california   \n",
       "3       berkeley, california   \n",
       "4        oakland, california   \n",
       "\n",
       "                                           offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, and doesn&rsquo;t wan...    straight   \n",
       "1                                                NaN    straight   \n",
       "2                            doesn&rsquo;t want kids         gay   \n",
       "3                            doesn&rsquo;t have kids    straight   \n",
       "4                            doesn&rsquo;t have kids    straight   \n",
       "\n",
       "                      pets                                   religion sex  \\\n",
       "0  likes dogs and has cats              atheism and laughing about it   m   \n",
       "1                      NaN              atheism and laughing about it   f   \n",
       "2                 has dogs       judaism but not too serious about it   f   \n",
       "3               likes dogs                                        NaN   m   \n",
       "4  has dogs and likes cats  christianity but not too serious about it   m   \n",
       "\n",
       "                                       sign  smokes  \\\n",
       "0                                       NaN      no   \n",
       "1                                       NaN      no   \n",
       "2                               sagittarius      no   \n",
       "3           leo but it doesn&rsquo;t matter     NaN   \n",
       "4  cancer and it&rsquo;s fun to think about      no   \n",
       "\n",
       "                                 speaks          status  \n",
       "0  english (fluently), spanish (poorly)          single  \n",
       "1                               english  seeing someone  \n",
       "2                               english          single  \n",
       "3    english (fluently), chinese (okay)          single  \n",
       "4                    english (fluently)          single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_profiles.csv\")\n",
    "df.columns\n",
    "\n",
    "# we must drop rows that do not have an education value to deal with missing values\n",
    "df = df[df.education.notnull()]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "labels = df['education']\n",
    "data = df.drop(columns=['education'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     17560\n",
       "age            17560\n",
       "body_type      16104\n",
       "diet           10797\n",
       "drinks         16942\n",
       "drugs          13494\n",
       "essay0         16115\n",
       "essay1         15616\n",
       "essay2         15001\n",
       "essay3         14415\n",
       "essay4         14839\n",
       "essay5         14718\n",
       "essay6         13821\n",
       "essay7         14198\n",
       "essay8         12237\n",
       "essay9         14114\n",
       "ethnicity      16056\n",
       "height         17560\n",
       "income         17560\n",
       "job            15898\n",
       "last_online    17560\n",
       "location       17560\n",
       "offspring       7409\n",
       "orientation    17560\n",
       "pets           12199\n",
       "religion       12182\n",
       "sex            17560\n",
       "sign           14733\n",
       "smokes         16236\n",
       "speaks         17547\n",
       "status         17560\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns that we found necessary to drop after examining the data manually. The reasons are listed below:\n",
    "\n",
    "- Removed 'Unnamed' because it is just a repeat of the index value\n",
    "- Removed essay0, essay1, essay2, essay3, essay4, essay5, essay6, essay7, essay8, and essay9 because they are paragraph answers and so every row will have a unique value (if we wanted to use this, we would have to do sentiment analysis or something similar)\n",
    "- Removed 'last_online' as it can't be used to predict the label (education)\n",
    "- Removed 'sign' as it can't be used to predict the label (education)\n",
    "- Removed 'offspring' as too many rows have NaN as a value\n",
    "- Removed 'diet' as too many rows have NaN as a value\n",
    "- Removed 'speaks' as there are too many distinct values and cannot be mapped into a smaller domain\n",
    "- Removed 'location' as there art too many distinct values and it cannot be used to predict the label (educatin)\n",
    "- Removed 'status' as there is a heavy class imbalance with almost all of the values being 'single'\n",
    "- Removed 'income' as almost all values are not listed (value appears as -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Unnamed: 0', 'essay0', 'essay1','essay2','essay3','essay4','essay5','essay6','essay7'\n",
    "                  ,'essay8','essay9','last_online','sign','offspring', 'diet', 'speaks','location','status', 'income'],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring and removing those columns from the data, we can now take a look at the columns that we kept, as well as the labels. We found that a lot of values would overlap, or there would just be too many possible values to glean meaningful information from someone's answer. Therefore, most of the columns needed to map values to a smaller subset of values. We start with our labels here, refining them to the values we think would be valuable to predict. As a side note, 'space camp' here is a joke value that OKCupid allows users to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to consolidate the labels for education\n",
    "label_engineering = {\n",
    "    'graduated from college/university': 'bachelors',\n",
    "    'greatued from masters program': 'advanced degree',\n",
    "    'working on college/university': 'bachelors',\n",
    "    'working on masters program': 'advanced degree',\n",
    "    'graduated from two-year college': 'associates',\n",
    "    'graduated from high school': 'high-school',\n",
    "    'graduated from ph.d program': 'advanced degree',\n",
    "    'graduated from law school': 'advanced degree',\n",
    "    'working on two-year college': 'associates',\n",
    "    'working on ph.d program': 'advanced degree',\n",
    "    'dropped out of college/university': 'high-school',\n",
    "    'college/university': 'bachelors',\n",
    "    'graduated from space camp': 'spacecamp',\n",
    "    'dropped out of space camp': 'spacecamp',\n",
    "    'graduated from med school': 'advanced degree',\n",
    "    'working on space camp': 'spacecamp',\n",
    "    'working on law school': 'advanced degree',\n",
    "    'working on med school': 'advanced degree',\n",
    "    'dropped out of two-year college': 'high-school',\n",
    "    'two-year college': 'associates',\n",
    "    'masters program': 'advanced degree',\n",
    "    'dropped out of masters program': 'advanced degree',\n",
    "    'dropped out of ph.d program': 'advanced degree',\n",
    "    'high school': 'high-school',\n",
    "    'dropped out of high school': 'high-school',\n",
    "    'working on high school': 'high-school',\n",
    "    'space camp': 'spacecamp',\n",
    "    'ph.d program': 'advanced degree',\n",
    "    'med school': 'advanced degree',\n",
    "    'law school': 'advanced degree',\n",
    "    'dropped out of law school': 'advanced degree',\n",
    "    'dropped out of med school': 'advanced degree',\n",
    "    'graduated from masters program': 'advanced degree'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.replace(label_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bachelors          9990\n",
       "advanced degree    5122\n",
       "associates          953\n",
       "high-school         946\n",
       "spacecamp           549\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have consolidated our education labels, we can move on to our dataset, where we will need to fill in missing values and consolidate the range of values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            17560\n",
       "body_type      16104\n",
       "drinks         16942\n",
       "drugs          13494\n",
       "ethnicity      16056\n",
       "height         17560\n",
       "job            15898\n",
       "orientation    17560\n",
       "pets           12199\n",
       "religion       12182\n",
       "sex            17560\n",
       "smokes         16236\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns for age, sex, and orientation are all full, so we won't need to fill in missing values, but we will still check the values and do the mappings. We start with the age column, and upon inspection it appears to be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    1113\n",
       "26    1100\n",
       "28    1076\n",
       "25    1035\n",
       "29    1011\n",
       "24     979\n",
       "30     906\n",
       "23     805\n",
       "32     791\n",
       "31     786\n",
       "33     651\n",
       "22     561\n",
       "34     559\n",
       "35     494\n",
       "36     471\n",
       "37     403\n",
       "38     383\n",
       "21     348\n",
       "39     328\n",
       "40     308\n",
       "42     283\n",
       "20     270\n",
       "41     269\n",
       "43     230\n",
       "44     220\n",
       "45     182\n",
       "46     169\n",
       "19     159\n",
       "48     157\n",
       "47     147\n",
       "49     132\n",
       "50     120\n",
       "51     106\n",
       "52      96\n",
       "56      89\n",
       "55      82\n",
       "57      82\n",
       "54      74\n",
       "18      69\n",
       "53      66\n",
       "58      62\n",
       "59      58\n",
       "60      58\n",
       "63      51\n",
       "61      48\n",
       "62      43\n",
       "64      33\n",
       "65      31\n",
       "66      27\n",
       "67      16\n",
       "68      13\n",
       "69      10\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the unique values in the 'body_type' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average           4179\n",
       "fit               3869\n",
       "athletic          3526\n",
       "thin              1397\n",
       "curvy             1143\n",
       "a little extra     767\n",
       "skinny             504\n",
       "full figured       307\n",
       "overweight         133\n",
       "jacked             113\n",
       "used up            111\n",
       "rather not say      55\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 6% of the elements are missing a value for body_type. Given that 'average' is the mode of all the values and that it is safe to assume that the typical person has an \"average\" body type, we will fill the NaNs with 'average'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "athletic       7508\n",
       "average        5690\n",
       "overweight     2461\n",
       "underweight    1901\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate the values for the body_type column because a lot of them are redundant\n",
    "body_type_dictionary = {\n",
    "    'average': 'average',\n",
    "    'athletic': 'athletic',\n",
    "    'fit': 'athletic',\n",
    "    'thin': 'underweight',\n",
    "    'curvy': 'overweight',\n",
    "    'a little extra': 'overweight',\n",
    "    'skinny': 'underweight',\n",
    "    'full figured': 'overweight',\n",
    "    'jacked': 'athletic',\n",
    "    'overweight': 'overweight',\n",
    "    'used up': 'overweight',\n",
    "    'rather not say': 'average'\n",
    "}\n",
    "\n",
    "data['body_type'] = data['body_type'].fillna('average')\n",
    "data['body_type'] = data['body_type'].replace(body_type_dictionary)\n",
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'drinks' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "socially       12512\n",
       "rarely          1777\n",
       "often           1508\n",
       "not at all       948\n",
       "very often       112\n",
       "desperately       85\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical, we can't take an average. Instead, we check the mode, which in this column is \"socially\". The mode makes up about 70% of the total values in this column, so we will fill all NaNs with \"socially.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sometimes     13130\n",
       "rarely         1777\n",
       "often          1508\n",
       "never           948\n",
       "very often      197\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate the values for the drinks column because a lot of them are redundant\n",
    "drinks_dictionary = {\n",
    "    'socially': 'sometimes',\n",
    "    'often': 'often',\n",
    "    'rarely': 'rarely',\n",
    "    'not at all': 'never',\n",
    "    'desperately': 'very often',\n",
    "    'very often': 'very often'\n",
    "}\n",
    "\n",
    "data['drinks'] = data['drinks'].fillna('socially')\n",
    "data['drinks'] = data['drinks'].replace(drinks_dictionary)\n",
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'drugs' column and fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        11066\n",
       "sometimes     2311\n",
       "often          117\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical once again, we will use the mode, which is \"never\" for this column. It makes up for about 80% of reported values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        15132\n",
       "sometimes     2311\n",
       "often          117\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drugs'] = data['drugs'].fillna('never')\n",
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'ethnicity' column and fill in missing values. It is important to note here that there seem to be some records in our data that seem to be pranks. There are records that select all the available ethnicity values, this has a very very small probability is reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                                                                                               9769\n",
       "asian                                                                                               1835\n",
       "hispanic / latin                                                                                     839\n",
       "black                                                                                                578\n",
       "other                                                                                                486\n",
       "                                                                                                    ... \n",
       "asian, black, native american, hispanic / latin                                                        1\n",
       "asian, black, hispanic / latin, other                                                                  1\n",
       "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other       1\n",
       "asian, black, native american, hispanic / latin, white                                                 1\n",
       "asian, middle eastern, white, other                                                                    1\n",
       "Name: ethnicity, Length: 154, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for ethnicity and fill in missing values\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must again use the mode to fill in missing values for this categorical feature, which ends up being \"white\", making up about 50% of the total data. There was a lot of diversity in ethnicity, so we narrowed down the categories to white, asian, black, hispanic, native, pacific, mixed, and other. If only the second ethnicity is 'other', that means it might be insignificant enough to be ignored, and the row gets classified as the first ethnicity reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white       11480\n",
       "asian        2281\n",
       "mixed        1684\n",
       "hispanic      880\n",
       "black         622\n",
       "other         486\n",
       "pacific       107\n",
       "native         20\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_dictionary = {\n",
    "    'white': 'white',\n",
    "    'asian': 'asian',\n",
    "    'hispanic / latin': 'hispanic',\n",
    "    'black': 'black',\n",
    "    'other': 'other',\n",
    "    'indian': 'asian',\n",
    "    'white, other': 'white',\n",
    "    'middle eastern': 'asian',\n",
    "    'black, other': 'black',\n",
    "    'hispanic / latin, other': 'hispanic',\n",
    "    'pacific islander': 'pacific',\n",
    "    'asian, other': 'asian',\n",
    "    'native american': 'native',\n",
    "    'indian, other': 'asian',\n",
    "    'native american, other': 'native',\n",
    "    'pacific islander, other': 'pacific',\n",
    "    'middle eastern, other': 'asian'\n",
    "}\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].fillna('white')\n",
    "data['ethnicity'] = data['ethnicity'].replace(ethnicity_dictionary)\n",
    "\n",
    "data.loc[~data['ethnicity'].isin(['white', 'asian', 'hispanic', 'black', 'pacific', 'native', 'other']), 'ethnicity'] = 'mixed'\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'height' column, we decide to fill in missing values using the average height of the row's respective gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['height'] = df['height'].fillna(df.groupby('sex')['height'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'jobs' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                2246\n",
       "student                              1566\n",
       "science / tech / engineering         1515\n",
       "computer / hardware / software       1467\n",
       "artistic / musical / writer          1343\n",
       "sales / marketing / biz dev          1340\n",
       "medicine / health                    1147\n",
       "education / academia                 1134\n",
       "executive / management                730\n",
       "entertainment / media                 720\n",
       "banking / financial / real estate     687\n",
       "law / legal services                  432\n",
       "hospitality / travel                  396\n",
       "construction / craftsmanship          260\n",
       "clerical / administrative             240\n",
       "political / government                213\n",
       "rather not say                        128\n",
       "transportation                        108\n",
       "unemployed                             87\n",
       "retired                                76\n",
       "military                               63\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical, and quite a few people already did not want to reveal their job anyways, the empty fields are also clumped into the 'rather not say' category. We narrowed down the categories to student, STEM, arts, business, education, not working, and military because there were a lot of different jobs and a lot of them fall into an overlying category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STEM           4497\n",
       "other          4036\n",
       "business       3393\n",
       "arts           2708\n",
       "student        1566\n",
       "education      1134\n",
       "not working     163\n",
       "military         63\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dictionary = {\n",
    "    'other': 'other',\n",
    "    'student': 'student',\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    'artistic / musical / writer': 'arts',\n",
    "    'sales / marketing / biz dev': 'business',\n",
    "    'education / academia': 'education',\n",
    "    'medicine / health': 'STEM',\n",
    "    'banking / financial / real estate': 'business',\n",
    "    'executive / management': 'business',\n",
    "    'hospitality / travel': 'business',\n",
    "    'entertainment / media': 'arts',\n",
    "    'law / legal services': 'arts',\n",
    "    'clerical / administrative': 'business',\n",
    "    'political / government': 'arts', \n",
    "    'construction / craftsmanship': 'STEM',\n",
    "    'rather not say': 'other',\n",
    "    'transportation': 'STEM',\n",
    "    'unemployed': 'not working',\n",
    "    'retired': 'not working',\n",
    "    'military': 'military'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].fillna('rather not say')\n",
    "data['job'] = data['job'].replace(job_dictionary)\n",
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'pets' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes dogs and likes cats          4582\n",
       "likes dogs                         2175\n",
       "likes dogs and has cats            1333\n",
       "has dogs                           1286\n",
       "has dogs and likes cats             685\n",
       "likes dogs and dislikes cats        620\n",
       "has dogs and has cats               426\n",
       "has cats                            403\n",
       "likes cats                          307\n",
       "has dogs and dislikes cats          149\n",
       "dislikes dogs and likes cats         94\n",
       "dislikes dogs and dislikes cats      55\n",
       "dislikes cats                        37\n",
       "dislikes dogs and has cats           29\n",
       "dislikes dogs                        18\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of different combinations of liking, disliking or owning dogs or cats, so we narrowed it down to simply pets rather than dogs or cats. We also fill in NaNs with 'likes' as the average person does not mind pets (but we do not want to assume ownership)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes       13139\n",
       "owns         4311\n",
       "dislikes      110\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_dictionary = {\n",
    "    'likes dogs and likes cats': 'likes',\n",
    "    'likes dogs': 'likes',\n",
    "    'likes dogs and has cats': 'owns',\n",
    "    'has dogs': 'owns',\n",
    "    'has dogs and likes cats': 'owns',\n",
    "    'likes dogs and dislikes cats': 'likes',\n",
    "    'has cats': 'owns',\n",
    "    'has dogs and has cats': 'owns',\n",
    "    'likes cats': 'likes',\n",
    "    'dislikes dogs and dislikes cats': 'dislikes',\n",
    "    'has dogs and dislikes cats': 'owns',\n",
    "    'dislikes dogs and likes cats': 'likes',\n",
    "    'dislikes cats': 'dislikes',\n",
    "    'dislikes dogs and has cats': 'owns',\n",
    "    'dislikes dogs': 'dislikes'\n",
    "}\n",
    "\n",
    "data['pets'] = data['pets'].fillna('likes')\n",
    "data['pets'] = data['pets'].replace(pet_dictionary)\n",
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the 'religion' column for unique values and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agnosticism                                   855\n",
       "agnosticism but not too serious about it      812\n",
       "other                                         808\n",
       "agnosticism and laughing about it             793\n",
       "catholicism but not too serious about it      707\n",
       "other and laughing about it                   676\n",
       "atheism                                       626\n",
       "atheism and laughing about it                 623\n",
       "christianity but not too serious about it     605\n",
       "christianity                                  561\n",
       "other but not too serious about it            467\n",
       "judaism but not too serious about it          466\n",
       "atheism but not too serious about it          405\n",
       "catholicism                                   322\n",
       "christianity and somewhat serious about it    303\n",
       "atheism and somewhat serious about it         258\n",
       "other and somewhat serious about it           255\n",
       "catholicism and laughing about it             237\n",
       "agnosticism and somewhat serious about it     201\n",
       "judaism and laughing about it                 198\n",
       "christianity and very serious about it        190\n",
       "buddhism but not too serious about it         182\n",
       "atheism and very serious about it             181\n",
       "other and very serious about it               171\n",
       "judaism                                       170\n",
       "catholicism and somewhat serious about it     167\n",
       "buddhism and laughing about it                163\n",
       "buddhism and somewhat serious about it        119\n",
       "christianity and laughing about it            115\n",
       "buddhism                                      108\n",
       "agnosticism and very serious about it         105\n",
       "judaism and somewhat serious about it          97\n",
       "hinduism but not too serious about it          73\n",
       "catholicism and very serious about it          39\n",
       "hinduism                                       30\n",
       "buddhism and very serious about it             20\n",
       "hinduism and somewhat serious about it         18\n",
       "islam                                          14\n",
       "islam but not too serious about it             14\n",
       "hinduism and laughing about it                 13\n",
       "hinduism and very serious about it              4\n",
       "islam and somewhat serious about it             4\n",
       "judaism and very serious about it               4\n",
       "islam and laughing about it                     3\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The religion data in this dataset also includes the mentality of the person in terms with there religiousness. Ignoring the religious mentality, we narrowed down to the different religions (or lackthereof). We also filled the NaNs with not-listed and clumped it with 'other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not-listed    7755\n",
       "christian     3246\n",
       "agnostic      2766\n",
       "atheist       2093\n",
       "jewish         935\n",
       "buddhist       592\n",
       "hindu          138\n",
       "muslim          35\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate values for the religion column because there were a lot of redundant values\n",
    "religion_dictionary = {    \n",
    "    \"agnosticism but not too serious about it\": \"agnostic\",\n",
    "    \"agnosticism\": \"agnostic\",\n",
    "    \"agnosticism and laughing about it\": \"agnostic\",\n",
    "    \"other\": \"not-listed\",\n",
    "    \"atheism\": \"atheist\",\n",
    "    \"other and laughing about it\": \"not-listed\",\n",
    "    \"christianity\": \"christian\",\n",
    "    \"catholicism but not too serious about it\": \"christian\",\n",
    "    \"atheism and laughing about it\": \"atheist\",\n",
    "    \"christianity but not too serious about it\": \"christian\",\n",
    "    \"atheism but not too serious about it\": \"atheist\",\n",
    "    \"other but not too serious about it\": \"not-listed\",\n",
    "    \"judaism but not too serious about it\": \"jewish\",\n",
    "    \"catholicism\": \"christian\",\n",
    "    \"other and somewhat serious about it\": \"not-listed\",\n",
    "    \"catholicism and laughing about it\": \"christian\",\n",
    "    \"christianity and somewhat serious about it\": \"christian\",\n",
    "    \"atheism and somewhat serious about it\": \"atheist\",\n",
    "    \"buddhism and laughing about it\": \"buddhist\",\n",
    "    \"agnosticism and somewhat serious about it\": \"agnostic\",\n",
    "    \"judaism and laughing about it\": \"jewish\",\n",
    "    \"judaism\": \"jewish\",\n",
    "    \"atheism and very serious about it\": \"atheist\",\n",
    "    \"catholicism and somewhat serious about it\": \"christian\",\n",
    "    \"buddhism but not too serious about it\": \"buddhist\",\n",
    "    \"buddhism\": \"buddhist\",\n",
    "    \"christianity and very serious about it\": \"christian\",\n",
    "    \"other and very serious about it\": \"not-listed\",\n",
    "    \"christianity and laughing about it\": \"christian\",\n",
    "    \"agnosticism and very serious about it\": \"agnostic\",\n",
    "    \"buddhism and somewhat serious about it\": \"buddhist\",\n",
    "    \"hinduism but not too serious about it\": \"hindu\",\n",
    "    \"judaism and somewhat serious about it\": \"jewish\",\n",
    "    \"catholicism and very serious about it\": \"christian\",\n",
    "    \"hinduism and somewhat serious about it\": \"hindu\",\n",
    "    \"buddhism and very serious about it\": \"buddhist\",\n",
    "    \"hinduism\": \"hindu\",\n",
    "    \"islam\": \"muslim\",\n",
    "    \"islam but not too serious about it\": \"muslim\",\n",
    "    \"islam and very serious about it\": \"muslim\",\n",
    "    \"hinduism and laughing about it\": \"hindu\",\n",
    "    \"islam and somewhat serious about it\": \"muslim\",\n",
    "    \"hinduism and very serious about it\": \"hindu\",\n",
    "    \"judaism and very serious about it\": \"jewish\",\n",
    "    \"islam and laughing about it\": \"muslim\"\n",
    "}\n",
    "\n",
    "data['religion'] = data['religion'].fillna('not-listed')\n",
    "data['religion'] = data['religion'].replace(religion_dictionary)\n",
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'smokes' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                13313\n",
       "sometimes          1072\n",
       "when drinking       874\n",
       "yes                 568\n",
       "trying to quit      409\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for smokes and fill in missing values\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mode for this column is 'no', making up about 75% of the data. We accordingly fill in Nans with 'no'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                14637\n",
       "sometimes          1072\n",
       "when drinking       874\n",
       "yes                 568\n",
       "trying to quit      409\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'no' is the mode and makes up about 75% of the data, so we will fill NaNs with 'no'\n",
    "data['smokes'] = data['smokes'].fillna('no')\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We can convert some of the categorical features into numerical values because they are on an ordinal scale. This allows there to be a larger difference between values that are further away. For example, in the drinks column, 'often' is further from 'never' than 'sometimes' is. This conversion to numerical values for ordinal features allows us to incorporate this magnitude in difference rather than having the standard distance of 1 between different categorical features. We use ordinal features for all of the models we tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>job</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "      <td>2</td>\n",
       "      <td>atheist</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>64.0</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "      <td>atheist</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>63.0</td>\n",
       "      <td>other</td>\n",
       "      <td>gay</td>\n",
       "      <td>2</td>\n",
       "      <td>jewish</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>71.0</td>\n",
       "      <td>student</td>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>mixed</td>\n",
       "      <td>66.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>straight</td>\n",
       "      <td>2</td>\n",
       "      <td>christian</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  body_type  drinks  drugs ethnicity  height      job orientation  pets  \\\n",
       "0   47          2       3      0     white    75.0    other    straight     2   \n",
       "1   27          1       3      0     white    64.0    other    straight     1   \n",
       "2   43          0       2      0     white    63.0    other         gay     2   \n",
       "3   22          1       2      0     asian    71.0  student    straight     1   \n",
       "4   31          2       2      0     mixed    66.0     STEM    straight     2   \n",
       "\n",
       "     religion sex  smokes  \n",
       "0     atheist   m       0  \n",
       "1     atheist   f       0  \n",
       "2      jewish   f       0  \n",
       "3  not-listed   m       0  \n",
       "4   christian   m       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts some of the categorical features into values because they are ordinal\n",
    "def convert_ordinal(data):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    drugs_codes = {\n",
    "        'never': 0,\n",
    "        'sometimes': 1,\n",
    "        'often': 2\n",
    "    }\n",
    "\n",
    "    drinks_codes = {\n",
    "        'never': 0,\n",
    "        'rarely': 1,\n",
    "        'sometimes': 2,\n",
    "        'often': 3,\n",
    "        'very often': 4\n",
    "    }\n",
    "\n",
    "    smokes_codes = {\n",
    "        \"no\": 0,\n",
    "        \"when drinking\": 1,\n",
    "        \"trying to quit\": 2,\n",
    "        \"sometimes\": 3,\n",
    "        \"yes\": 4\n",
    "    }\n",
    "\n",
    "    pets_codes = {\n",
    "        \"dislikes\": 0,\n",
    "        \"likes\": 1,\n",
    "        \"owns\": 2\n",
    "    }\n",
    "    \n",
    "    body_codes = {\n",
    "        \"underweight\": 0,\n",
    "        \"average\": 1,\n",
    "        \"athletic\": 2,\n",
    "        \"overweight\": 3\n",
    "    }\n",
    "\n",
    "    copy['drugs'] = data['drugs'].replace(drugs_codes)\n",
    "    copy['drinks'] = data['drinks'].replace(drinks_codes)\n",
    "    copy['smokes'] = data['smokes'].replace(smokes_codes)\n",
    "    copy['pets'] = data['pets'].replace(pets_codes)\n",
    "    copy['body_type'] = data['body_type'].replace(body_codes)\n",
    "    return copy\n",
    "\n",
    "data = convert_ordinal(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models that we plan on using do not accept categorical data. Therefore, for the categorical features that are nominal and not ordinal, we are using one-hot encoding where applicable to be able to use these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>pets</th>\n",
       "      <th>smokes</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>religion_agnostic</th>\n",
       "      <th>religion_atheist</th>\n",
       "      <th>religion_buddhist</th>\n",
       "      <th>religion_christian</th>\n",
       "      <th>religion_hindu</th>\n",
       "      <th>religion_jewish</th>\n",
       "      <th>religion_muslim</th>\n",
       "      <th>religion_not-listed</th>\n",
       "      <th>sex_f</th>\n",
       "      <th>sex_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  body_type  drinks  drugs  height  pets  smokes  ethnicity_asian  \\\n",
       "0   47          2       3      0    75.0     2       0                0   \n",
       "1   27          1       3      0    64.0     1       0                0   \n",
       "2   43          0       2      0    63.0     2       0                0   \n",
       "3   22          1       2      0    71.0     1       0                1   \n",
       "4   31          2       2      0    66.0     2       0                0   \n",
       "\n",
       "   ethnicity_black  ethnicity_hispanic  ...  religion_agnostic  \\\n",
       "0                0                   0  ...                  0   \n",
       "1                0                   0  ...                  0   \n",
       "2                0                   0  ...                  0   \n",
       "3                0                   0  ...                  0   \n",
       "4                0                   0  ...                  0   \n",
       "\n",
       "   religion_atheist  religion_buddhist  religion_christian  religion_hindu  \\\n",
       "0                 1                  0                   0               0   \n",
       "1                 1                  0                   0               0   \n",
       "2                 0                  0                   0               0   \n",
       "3                 0                  0                   0               0   \n",
       "4                 0                  0                   1               0   \n",
       "\n",
       "   religion_jewish  religion_muslim  religion_not-listed  sex_f  sex_m  \n",
       "0                0                0                    0      0      1  \n",
       "1                0                0                    0      1      0  \n",
       "2                1                0                    0      1      0  \n",
       "3                0                0                    1      0      1  \n",
       "4                0                0                    0      0      1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode(data, column=None):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    if column is None:\n",
    "        to_encode = ['ethnicity', 'job', 'orientation', 'religion', 'sex']\n",
    "        for column in to_encode:\n",
    "            copy = one_hot_encode(copy, column)\n",
    "    else:\n",
    "        dummies = pd.get_dummies(copy[[column]])\n",
    "        copy = pd.concat([copy, dummies], axis=1)\n",
    "        copy = copy.drop([column], axis=1)\n",
    "        \n",
    "    return copy\n",
    "\n",
    "one_hot_encode(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the models that we plan on using are very sensitive to the effect of outliers, so we have to remove them in order for the models to function effectively. We are utilizing isolation forests with a 5% contamination rate to remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  body_type  drinks  drugs ethnicity  height      job orientation  pets  \\\n",
      "0   47          2       3      0     white    75.0    other    straight     2   \n",
      "1   27          1       3      0     white    64.0    other    straight     1   \n",
      "2   43          0       2      0     white    63.0    other         gay     2   \n",
      "3   22          1       2      0     asian    71.0  student    straight     1   \n",
      "4   31          2       2      0     mixed    66.0     STEM    straight     2   \n",
      "\n",
      "     religion sex  smokes  \n",
      "0     atheist   m       0  \n",
      "1     atheist   f       0  \n",
      "2      jewish   f       0  \n",
      "3  not-listed   m       0  \n",
      "4   christian   m       0   \n",
      "\n",
      "0          bachelors\n",
      "1          bachelors\n",
      "2    advanced degree\n",
      "3          bachelors\n",
      "4          bachelors\n",
      "Name: education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(data, labels):\n",
    "    data_cp = data.copy()\n",
    "    labels_cp = labels.copy()\n",
    "    \n",
    "    iso_forest = ensemble.IsolationForest(n_estimators=100, contamination=0.05)\n",
    "    pred = iso_forest.fit_predict(data_cp.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex']))\n",
    "    pred = pd.Series(pred)\n",
    "    data_cp = data_cp[pred == 1].reset_index(drop=True)\n",
    "    labels_cp = labels_cp[pred == 1].reset_index(drop=True)\n",
    "    \n",
    "    return (data_cp, labels_cp)\n",
    "\n",
    "data_cp, labels_cp = remove_outliers(data, labels)\n",
    "print(data_cp.head(), '\\n')\n",
    "print(labels_cp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to try balanced data for certain models due to there being too few of certain labels. We upsample and downsample accordingly in an attempt to even out any class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  body_type  drinks  drugs ethnicity  height    job orientation  pets  \\\n",
      "0   32          2       2      0     white    70.0  other    straight     1   \n",
      "1   35          2       2      0     white    68.0   arts    straight     1   \n",
      "2   20          0       3      0     white    66.0   arts    straight     1   \n",
      "3   41          2       2      0     white    71.0   arts    straight     2   \n",
      "4   36          2       2      1     white    75.0   STEM    straight     1   \n",
      "\n",
      "     religion sex  smokes  \n",
      "0  not-listed   m       0  \n",
      "1  not-listed   f       0  \n",
      "2  not-listed   f       0  \n",
      "3  not-listed   m       0  \n",
      "4  not-listed   m       3   \n",
      "\n",
      "0    advanced degree\n",
      "1    advanced degree\n",
      "2         associates\n",
      "3          spacecamp\n",
      "4          spacecamp\n",
      "Name: education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def balance_data(data, labels, rows=None):\n",
    "    if rows is None:\n",
    "        rows = len(data.index) // len(labels.unique())\n",
    "    \n",
    "    all_data = pd.concat([data, labels], axis=1)\n",
    "    unique_labels = labels.unique()\n",
    "    \n",
    "    to_concat = []\n",
    "    for label in unique_labels:\n",
    "        num_label = len(all_data[all_data['education']==label].index)\n",
    "        if num_label > rows:\n",
    "            #downsample\n",
    "            down = all_data[all_data['education']==label].sample(n=rows)\n",
    "            to_concat.append(down)\n",
    "        elif num_label < rows:\n",
    "            #upsample\n",
    "            choices = all_data[all_data['education']==label]\n",
    "            indices = np.array(choices.index)\n",
    "            resampled_indices = np.random.choice(indices, size=rows, replace=True)\n",
    "            up = choices.loc[resampled_indices]\n",
    "            to_concat.append(up)\n",
    "    \n",
    "    new_df = pd.concat(to_concat, axis=0).sample(frac=1).reset_index(drop=True)\n",
    "    new_labels = new_df['education']\n",
    "    new_data = new_df.drop(columns=['education'])\n",
    "    \n",
    "    return new_data, new_labels\n",
    "\n",
    "data_balanced, labels_balanced = balance_data(data, labels)\n",
    "print(data_balanced.head(), '\\n')\n",
    "print(labels_balanced.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "The first model we tried was a KNN classifier. It's a common classifier and we decided to start out seeing what accuracy we could get with it. KNN could be sensitive to outliers because these points may be very far from most data points distance wise, and may not be classified correctly. Additionally, KNN breaks down in higher dimensionality, so we opted not to one hot encode the nominal features and instead completely drop them. Lastly, we used a balanced dataset to account for the class imbalance. The class imbalance is not good for the KNN, as there will probabilistically be more neighbors of the dominant label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5887290167865707\n",
      "Weighted F1: 0.5670520939031272\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "knn_data, knn_labels = remove_outliers(data, labels)\n",
    "knn_data = knn_data.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex'])\n",
    "knn_data, knn_labels = balance_data(knn_data, knn_labels)\n",
    "\n",
    "param_grid = {'pca__n_components': [val / 20 for val in range(12, 20)], 'knn__n_neighbors': list(range(5, 10))}\n",
    "inner = model_selection.GridSearchCV(ppl, param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "pred = model_selection.cross_val_predict(inner, knn_data, knn_labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(knn_labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(knn_labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balancing of data does introduce one problem -- the final accuracy evaluated will be slightly skewed to the higher side because of the upsampled data contributing many more true positives and true negatives than they are supposed to. This is probably avoidable if the data is trained according to the balanced dataset, but evaluated against the original dataset. However, the KNN produced the highest accuracy (68%) and F1 score (0.64) of all the models we tried when we ran on the sample data set (1782 records), but on the overall data, it seems to be performing similar to the rest of our models, with the exception of a slightly better F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "We decided to try a decision tree next, as they can handle categorical data better as they can be split along the unique values. Decision trees do not break down in high dimensionality, which is a benefit for us as we have a large number of features that get introduced because of the one-hot encoding. One-hot encoding performed better than altogether removing the nominal features, which indicates that there is some information in these features that could be extracted by classifiers that can better handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5847949886104784\n",
      "Weighted F1: 0.5019257731825983\n"
     ]
    }
   ],
   "source": [
    "tree_data = one_hot_encode(data)\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'min_samples_leaf': [val / 200 for val in range(1, 11)]}\n",
    "inner = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "pred = model_selection.cross_val_predict(inner, tree_data, labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just the accuracy of the decision tree seemed to provide false information. We got an accuracy between 56% and 58% on average. However the weighted F1 score (weighted to account for the class imbalance) was much lower at around 48-50%. This indicates that either our precision, recall, or both, especially for the dominant class (i.e. bachelors), is not very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMs\n",
    "\n",
    "For SVMs, we tried multiple different models, including SVC and LinearSVC, in combination with both one vs one approach, and one vs rest approach, with or without balanced data. We decided to remove outliers for the SVMs because they will greatly influence the cost function, which is not something we would want. Additionally, we chose not to one hot encode the data because of the curse of dimensionality also applying to SVMs.\n",
    "\n",
    "<B>Note</B>: SVMs were only run using the test set. The SVMs took almost 2 hours to run just with the test set. With the accuracy that we observed (as seen below), we felt it was not worth the time to run it on the final data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs One accuracy: 0.35815602836879434\n",
      "One vs One weighted F1: 0.36026139063452167\n",
      "One vs Rest accuracy: 0.38416075650118203\n",
      "One vs Rest weighted F1: 0.42131740872006374\n"
     ]
    }
   ],
   "source": [
    "def run_multiclass_svm_model(data, labels, outer_model, name):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('clf', outer_model)])\n",
    "    \n",
    "    svm_data, svm_labels = remove_outliers(data, labels)\n",
    "    svm_data = svm_data.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex'])\n",
    "\n",
    "    inner_clfs = [svm.SVC(kernel=type, class_weight='balanced') for type in ['linear', 'poly', 'sigmoid', 'rbf']]\n",
    "    inner_clfs.extend([svm.LinearSVC(loss=type, class_weight='balanced') for type in ['hinge', 'squared_hinge']])\n",
    "    param_grid = {'pca__n_components': [val / 10 for val in range(6, 10)], 'clf__estimator': inner_clfs}\n",
    "    \n",
    "    inner = model_selection.GridSearchCV(ppl, param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "    pred = model_selection.cross_val_predict(inner, svm_data, svm_labels, cv=5)\n",
    "    print(name, 'accuracy:', metrics.accuracy_score(svm_labels, pred))\n",
    "    print(name, 'weighted F1:', metrics.f1_score(svm_labels, pred, average='weighted'))\n",
    "\n",
    "run_multiclass_svm_model(data, labels, multiclass.OneVsOneClassifier(None), 'One vs One')\n",
    "run_multiclass_svm_model(data, labels, multiclass.OneVsRestClassifier(None), 'One vs Rest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced SVC accuracy 0.36997635933806144\n",
      "Balanced SVC weighted F1 0.40520373244710955\n",
      "Unbalanced SVC accuracy 0.5236406619385343\n",
      "Unbalanced SVC weighted F1 0.4829922891879866\n"
     ]
    }
   ],
   "source": [
    "def run_svc_model(data, labels, balanced):\n",
    "    weight = 'balanced' if balanced else None\n",
    "    score = 'accuracy' if balanced else 'f1_weighted'\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    svc = svm.SVC(class_weight=weight)\n",
    "    ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('svm', svc)])\n",
    "\n",
    "    svm_data, svm_labels = remove_outliers(data, labels)\n",
    "    svm_data = svm_data.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex'])\n",
    "\n",
    "    kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "    costs = [1.0, 10.0, 100.0]\n",
    "    param_grid = {'svm__kernel': kernels, 'svm__C': costs, 'svm__decision_function_shape': ['ovo', 'ovr']}\n",
    "\n",
    "    inner = model_selection.GridSearchCV(ppl, param_grid, scoring=score, cv=5, iid=True)\n",
    "    pred = model_selection.cross_val_predict(inner, svm_data, svm_labels, cv=5)\n",
    "    \n",
    "    name = 'Balanced' if balanced else 'Unbalanced'\n",
    "    print(name, 'SVC accuracy', metrics.accuracy_score(svm_labels, pred))\n",
    "    print(name, 'SVC weighted F1', metrics.f1_score(svm_labels, pred, average='weighted'))\n",
    "\n",
    "run_svc_model(data, labels, True)\n",
    "run_svc_model(data, labels, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the SVC accuracy on balanced data was significantly lower than on unbalanced data. Balancing the data upsampled or downsampled data from certain classes based on the parameter. Given the heavy class imbalance favoring bachelors, it makes sense why a balanced SVM that used data that downsampled bachelors data and upsampled data from other classes would have a lower accuracy as now it could be overfitting to elements from underrepresented classes, causing those to be predicted more. \n",
    "\n",
    "The unbalanced SVC had a slightly lower accuracy than the neural network and the decision tree, but was still worse than the KNN model. However, the downside of the SVC was that it took very long to run. As mentioned above, it took about 2 hours to run on our smaller test dataset (1782 records). This is likely because of the multiclass aspect of our dataset. It is harder for the SVM algorithm to find concurrent hyperplanes to divide the data into multiple hyperspaces than to find a single hyperspace. SVM does not seem to be a good choice for multiclass problems where data is not well clustered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "We also wanted to try a naive bayes model. Since we don't know the distribution of the data, we tried both GaussianNB and MultinomialNB. The model accuracy was understandably extremely poor with one hot encoding because of too many small probabilities introduced with the new one hot encoded features, so we just dropped the nominal features completely. There are no specific hyperparameters of interest, so we chose not to perform a GridSearchCV on the naive bayes algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB accuracy: 0.5314350797266515\n",
      "GaussianNB weighted F1: 0.5028811553148655\n",
      "MultinomialNB accuracy: 0.539123006833713\n",
      "MultinomialNB weighted F1: 0.4959527808210238\n"
     ]
    }
   ],
   "source": [
    "def run_naive_bayes(data, labels, isGaussianNB):\n",
    "    if isGaussianNB:\n",
    "        classifier = naive_bayes.GaussianNB()\n",
    "        classifier_roc_curve = naive_bayes.GaussianNB()\n",
    "    else:\n",
    "        classifier = naive_bayes.MultinomialNB()\n",
    "        classifier_roc_curve = naive_bayes.MultinomialNB()\n",
    "    \n",
    "    bayes_data = data.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex'])\n",
    "    \n",
    "    pred = model_selection.cross_val_predict(classifier, bayes_data, labels, cv=10)\n",
    "    \n",
    "    name = 'GaussianNB' if isGaussianNB else 'MultinomialNB'\n",
    "    print(name, 'accuracy:', metrics.accuracy_score(labels, pred))\n",
    "    print(name, 'weighted F1:', metrics.f1_score(labels, pred, average='weighted'))\n",
    "\n",
    "run_naive_bayes(data, labels, True)\n",
    "run_naive_bayes(data, labels, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB is typically used when features have a normal distribution and are continuous. In the case of this dataset, the data isn't really continous except for features such as height, so that would explain the relatively lower accuracy, both in terms of comparison to multinomial and to other models.\n",
    "\n",
    "MultinomialNB is typically used with discrete data, which is primarily the case for this dataset, explaining the slightly improved accuracy over Gaussian. However, we believe that the accuracy measure, F1-Score, is lower in comparison to other models, because naive bayes takes a probabilistic approach to prediction. In our dataset, probability may not often be meaningful when considering it just in terms of binary correlation between each feature and the education label. As an example, it is equally as likely that someone is 6 feet tall given that they have an advanced degree and that someone is 6 feet tall and holds a bachelors degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "Neural networks are often a good option for predictive models, so we decided to try that as well. We chose to one hot encode the data for neural networks to maximize the number of nodes being used at each layer as determined by the multilayer perceptron classifier's algorithm. This could allow for more intricate correlations between features to be picked up, but may also cause underfitting because of picking up unimportant correlations. We also chose to remove outliers as they could cause the loss function to evaluate such that weights would have to be shifted by a large amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5909962834192543\n",
      "Weighted F1: 0.5264157505793133\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "nn = neural_network.MLPClassifier()\n",
    "ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('nn', nn)])\n",
    "\n",
    "nn_data, nn_labels = remove_outliers(data, labels)\n",
    "nn_data = one_hot_encode(nn_data)\n",
    "\n",
    "param_grid = {'nn__activation': ['logistic', 'tanh', 'relu'], 'nn__solver': ['sgd', 'adam'], 'nn__learning_rate': ['constant', 'adaptive']}\n",
    "inner = model_selection.GridSearchCV(ppl, param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "pred = model_selection.cross_val_predict(inner, nn_data, nn_labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(nn_labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(nn_labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found an accuracy of about 59%, which was comparable to the decision tree, and our highest for the final data set. We believe that NNs worked relatively well because they weigh features that have importance with a heavier weight value, finding the essential features while diminishing the impact that a less important feature, say pets, may have in predicting education. This is different than a Decision Tree in that a Decision Tree splits upon any discrete variable, and while the end leaves may have the same label, there is a possibility that they have different predicted classes. NNs can remove that possibility through providing weights to the deemed 'essential or important' features that are more important in predictions. NNs also had the advantage of not breaking down in higher dimensions, which might have happened in some of the other models because of the large number of features in our data when exacerbated by the one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "Ensembles made sense to test last, since we now have several different classifiers which we can put together. We chose to test the random forest ensemble, the ada boost ensemble, and also the voting ensemble. The random forest and ada boost also perform voting, but they purely use decision trees as their estimators. We also decided to try the voting ensemble because we had tested the other classifiers and had seen which ones had performed better. We expect ensembles to work because of the nature of different classifiers to pick up correlations in different parts of the data set, and not be completely overlapping in which data points they predict correctly (should have a little but not a lot of overlap to be effective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_data, ensemble_labels = remove_outliers(data, labels)\n",
    "ensemble_data = one_hot_encode(ensemble_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5917156216281021\n",
      "Weighted F1: 0.5007874483451646\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [25,30,35,40], 'min_samples_leaf': [0.002,0.005,0.01], 'max_features': ('sqrt','log2')}\n",
    "inner = model_selection.GridSearchCV(ensemble.RandomForestClassifier(n_estimators=100), param_grid, scoring='accuracy', cv=5)\n",
    "pred = model_selection.cross_val_predict(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(ensemble_labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(ensemble_labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5945330296127562\n",
      "Weighted F1: 0.5180353583944314\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150], 'learning_rate': [0.7, 0.85, 1.0]}\n",
    "inner = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, scoring='accuracy', cv=5)\n",
    "pred = model_selection.cross_val_predict(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(ensemble_labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(ensemble_labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting\n",
    "\n",
    "For the voting ensemble, we used the KNN, decision tree, neural network, and unbalanced SVC. One of the set of weights used in hyperparameters testing was estimated based on how well each classifier had performed individually during the test set phase, and another set of weights was based on final set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.566358949766215\n",
      "Weighted F1: 0.5158715609560718\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('knn', pipeline.make_pipeline(preprocessing.StandardScaler(), decomposition.PCA(n_components=7), neighbors.KNeighborsClassifier())),\n",
    "    ('dt', tree.DecisionTreeClassifier()),\n",
    "    ('nn', pipeline.make_pipeline(preprocessing.MinMaxScaler(), neural_network.MLPClassifier())),\n",
    "    ('svc', pipeline.make_pipeline(preprocessing.StandardScaler(), decomposition.PCA(n_components=7), svm.SVC(decision_function_shape='ovr')))\n",
    "]\n",
    "\n",
    "param_grid = {'weights': [[1, 1, 1, 1], [1, 0.7, 0.7, 0.5], [1, 1, 1, 0.7]]}\n",
    "inner = model_selection.GridSearchCV(ensemble.VotingClassifier(estimators=estimators), param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "pred = model_selection.cross_val_predict(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', metrics.accuracy_score(ensemble_labels, pred))\n",
    "print('Weighted F1:', metrics.f1_score(ensemble_labels, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the voting ensemble turned out to be around the average of the ensembled classifiers. This is potentially indicative of the different classifiers overlapping in what classes they predict for certain points. For an ensemble, it would be preferable that the classifiers to have higher accuracy in different parts of the data so that there is a wider coverage to perform the voting over, especially for the Random Forest and the Voting classifiers. This does not seem to be the case with our dataset; there probably is a lot of uncertainty in a large proportion of the data, where no classifier is able to provide correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Most of our models had accuracies between 55% and 60%. Our data was primarily categorical and had to be scaled using one-hot encoding, which increased our number of features. By increasing the number of dimensions, our models and predictive algorithms fell prey to the curse of dimensionality. Additionally, we were attempting to predict one of 5 different labels, which makes it difficult to predict with a high accuracy, especially given that our data was primarily categorical, and many models perform better on binary classification problems. Given these circumstances, we believe that our predictive algorithms are relatively accurate, but not necessarily usable, and can probably be improved upon with additional data exploration and feature engineering.\n",
    "\n",
    "In our dataset, there was a heavy class imbalance favoring 'bachelors'. This class made up about 60% of the data. Additionally, using domain knowledge of real life experiences, it seems very difficult to predict someone's education level based on factors such as religion, whether or not they smoke or drink, body type, preference for pets, and height. It is possible for someone of any religion to have any level of education and someone who is tall or short could receive their ph.d. Features such as income and job are far better indicators of education level. The problem we faced with income was that the majority of values were missing, as a lot of people probably did not want to self-report income on a dating app. The problem we faced with job/occupation was that there were a a lot of unique values, which would further worsen the curse of dimensionality. Even with the given values, the job values were very vague and didn't give any specific role details that could be used to predict education. For example, there was a value of 'entertainment'. This could include the most succesful singers in the world who make millions of dollars or a local band member who was still in high school. We also found another potential source of error could come from the fact that the data was self reported. This means that if someone was embarrased or thought a factor about themselves, such as body type, was unattractive, they would not report it. This could lead to a lot of significant or differentiating factors to be missing. Since on a dating website, people are encouraged to portray the best version of themselves to make themselves attractive to potential partners. Therefore, there\n",
    "may be inaccuracies in some of the data, especially in features such as height, and body type where people\n",
    "might lie, affecting the models that we use.\n",
    "\n",
    "Another aspect that we found to complicate predicting the labels was that one of the classes was 'space camp'. We were not sure why this was an option and is it clearly did not indicate a real or serious education level, but felt that we should not remove the elements that belonged to the 'space camp' class as it was not insignificant. Given that this was a fake class, predicting this class was difficult as there are no real factors that indicate whether someone's education level was space camp. Two elements could have the exact same attributes and one could have a class of 'advanced degree' while the other could have a class of 'space camp', which simply confuses any model or algorithm.\n",
    "\n",
    "\n",
    "All in all, while we were able to predict the education level around a 68% accuracy, we cannot conclude that there is necessarily a strong correlation between the features that we explored and the education level. Given the imbalance favoring 'bachelors', predicting 'bachelors' for every element would result in a similar accuracy. However, we did find that our predictions were not just 'bachelors', which was only predicted 60 - 75% of the time, and that the F1 scores were not very bad. This is a good sign that our models did fit to the data and find some level of correlation between the features and the labels and were not completely overfitted to the class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
