{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s): Ojas Patel (ovp74), Pranav Neravetla (prn289), Suhas Dara, Avinash Damania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKCupid Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will use an OKCupid dataset to solve the problem of predicting education level using information from dating profiles such as physical traits and lifestyle choices. Predicting someone's education level from their dating profile is useful for those with dating preferences. When making a profile, people will often avoid filling out certain fields, meaning that someone could match most of your preferences but be at a different stage of their education or career. For those who would prefer dating someone they can more strongly relate to in terms of school/work, predicting their education level can be quite valuable.\n",
    "\n",
    "The OKCupid dataset we will use contains 19782 profiles from various residents of California. These profiles each have several different attributes that describe the person, such as age, body type, diet, and more. These attributes will be the basis of our predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Some headers\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing, decomposition, neighbors, pipeline, tree, svm, multiclass\n",
    "from sklearn import naive_bayes, neural_network, ensemble, metrics, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Exploration\n",
    "\n",
    "In this section, we will clean and engineer the data in preparation for use in training our models. Some of the tasks necessary include dropping unusable attributes, checking for missing values, feature engineering, removing outliers, and looking for potential class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep\n",
    "\n",
    "For the sake of efficiency while developing our models, we used a downsampled data set from test_profiles.csv. Our\n",
    "\n",
    "In the event that a row does not have a value for education, we must drop it, since we need labeled data for training testing. Otherwise, we form our data and label sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>i'm looking to meet someone who i have a lot i...</td>\n",
       "      <td>i work in the tech industry during the day, an...</td>\n",
       "      <td>i'm an expert at scrabble, designing ambigrams...</td>\n",
       "      <td>my lip ring, which i use to distract people fr...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and has cats</td>\n",
       "      <td>christianity and laughing about it</td>\n",
       "      <td>m</td>\n",
       "      <td>taurus but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), chinese (fluently), japane...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>they say i'm a smart, funny, worldly girl who ...</td>\n",
       "      <td>i'm transitioning from a lost, once ambitious ...</td>\n",
       "      <td>listening&lt;br /&gt;\\n&lt;br /&gt;\\nnot judging others&lt;br...</td>\n",
       "      <td>eyes&lt;br /&gt;\\n&lt;br /&gt;\\nsmile&lt;br /&gt;\\n&lt;br /&gt;\\nthoug...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>aries and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>update: i am in bmore/philly till may 27th for...</td>\n",
       "      <td>i'm self-employed events technician and it's w...</td>\n",
       "      <td>being a smart ass, saying inappropriate things...</td>\n",
       "      <td>my charming good looks and the piece of lettuc...</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), swedish (okay), spanish (p...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gay</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>other</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english, spanish (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hmmi freely give compliments. i appreciate a g...</td>\n",
       "      <td>i'm a teacher by day and i usually love it. i'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>taurus and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age body_type             diet      drinks      drugs  \\\n",
       "0           0   28  athletic  mostly anything    socially  sometimes   \n",
       "1           1   34   average  mostly anything    socially      never   \n",
       "2           2   29       fit  mostly anything    socially      never   \n",
       "3           3   45  athletic              NaN  not at all      never   \n",
       "4           4   37   average              NaN    socially        NaN   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  i'm looking to meet someone who i have a lot i...   \n",
       "1  they say i'm a smart, funny, worldly girl who ...   \n",
       "2  update: i am in bmore/philly till may 27th for...   \n",
       "3                                                NaN   \n",
       "4  hmmi freely give compliments. i appreciate a g...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  i work in the tech industry during the day, an...   \n",
       "1  i'm transitioning from a lost, once ambitious ...   \n",
       "2  i'm self-employed events technician and it's w...   \n",
       "3                                                NaN   \n",
       "4  i'm a teacher by day and i usually love it. i'...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  i'm an expert at scrabble, designing ambigrams...   \n",
       "1  listening<br />\\n<br />\\nnot judging others<br...   \n",
       "2  being a smart ass, saying inappropriate things...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay3   ...    \\\n",
       "0  my lip ring, which i use to distract people fr...   ...     \n",
       "1  eyes<br />\\n<br />\\nsmile<br />\\n<br />\\nthoug...   ...     \n",
       "2  my charming good looks and the piece of lettuc...   ...     \n",
       "3                                                NaN   ...     \n",
       "4                                                NaN   ...     \n",
       "\n",
       "                    location offspring orientation                       pets  \\\n",
       "0  san francisco, california       NaN    straight    likes dogs and has cats   \n",
       "1  san francisco, california       NaN    straight    has dogs and likes cats   \n",
       "2        oakland, california       NaN    straight  likes dogs and likes cats   \n",
       "3  san francisco, california       NaN         gay  likes dogs and likes cats   \n",
       "4  san francisco, california       NaN    straight                        NaN   \n",
       "\n",
       "                             religion sex  \\\n",
       "0  christianity and laughing about it   m   \n",
       "1                                 NaN   f   \n",
       "2                                 NaN   m   \n",
       "3                               other   m   \n",
       "4                                 NaN   f   \n",
       "\n",
       "                                       sign  smokes  \\\n",
       "0        taurus but it doesn&rsquo;t matter      no   \n",
       "1   aries and it&rsquo;s fun to think about      no   \n",
       "2                                       NaN      no   \n",
       "3                                    cancer      no   \n",
       "4  taurus and it&rsquo;s fun to think about      no   \n",
       "\n",
       "                                              speaks  status  \n",
       "0  english (fluently), chinese (fluently), japane...  single  \n",
       "1                                            english  single  \n",
       "2  english (fluently), swedish (okay), spanish (p...  single  \n",
       "3                          english, spanish (poorly)  single  \n",
       "4                                            english  single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_profiles.csv\")\n",
    "df.columns\n",
    "\n",
    "# we must drop rows that do not have an education value to deal with missing values\n",
    "df = df[df.education.notnull()]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "label = df['education']\n",
    "data = df.drop(columns=['education'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     1782\n",
       "age            1782\n",
       "body_type      1635\n",
       "diet           1082\n",
       "drinks         1727\n",
       "drugs          1392\n",
       "essay0         1615\n",
       "essay1         1572\n",
       "essay2         1530\n",
       "essay3         1469\n",
       "essay4         1509\n",
       "essay5         1497\n",
       "essay6         1429\n",
       "essay7         1451\n",
       "essay8         1235\n",
       "essay9         1453\n",
       "ethnicity      1627\n",
       "height         1782\n",
       "income         1782\n",
       "job            1609\n",
       "last_online    1782\n",
       "location       1782\n",
       "offspring       757\n",
       "orientation    1782\n",
       "pets           1230\n",
       "religion       1243\n",
       "sex            1782\n",
       "sign           1511\n",
       "smokes         1645\n",
       "speaks         1780\n",
       "status         1782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns that we found necessary to drop after examining the data manually. The reasons are listed below:\n",
    "\n",
    "- removed 'Unnamed' because it is just a repeat of the index value\n",
    "- removed essay0, essay1, essay2, essay3, essay4, essay5, essay6, essay7, essay8, and essay9 because they are paragraph answers and so every row will have a unique value (if we wanted to use this, we would have to do sentiment analysis or something similar)\n",
    "- removed 'last_online' as it can't be used to predict the label (education)\n",
    "- removed 'sign' as it can't be used to predict the label (education)\n",
    "- removed 'offspring' as too many rows have NaN as a value\n",
    "- removed 'diet' as too many rows have NaN as a value\n",
    "- removed 'speaks' as there are too many distinct values and cannot be mapped into a smaller domain\n",
    "- removed 'location' as there art too many distinct values and it cannot be used to predict the label (educatin)\n",
    "- removed 'status' as there is a heavy class imbalance with almost all of the values being 'single'\n",
    "- removed 'income' as almost all values are not listed (value appears as -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Unnamed: 0', 'essay0', 'essay1','essay2','essay3','essay4','essay5','essay6','essay7'\n",
    "                  ,'essay8','essay9','last_online','sign','offspring', 'diet', 'speaks','location','status', 'income'],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring and removing those columns from the data, we can now take a look at the columns that we kept, as well as the labels. We found that a lot of values would overlap, or there would just be too many possible values to glean meaningful information from someone's answer. Therefore, most of the columns needed to map values to a smaller subset of values. We start with our labels here, refining them to the values we think would be valuable to predict. As a side note, 'space camp' here is a joke value that OKCupid allows users to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to consolidate the labels for education\n",
    "label_engineering = {\n",
    "    'graduated from college/university': 'bachelors',\n",
    "    'greatued from masters program': 'advanced degree',\n",
    "    'working on college/university': 'bachelors',\n",
    "    'working on masters program': 'advanced degree',\n",
    "    'graduated from two-year college': 'associates',\n",
    "    'graduated from high school': 'high-school',\n",
    "    'graduated from ph.d program': 'advanced degree',\n",
    "    'graduated from law school': 'advanced degree',\n",
    "    'working on two-year college': 'associates',\n",
    "    'working on ph.d program': 'advanced degree',\n",
    "    'dropped out of college/university': 'high-school',\n",
    "    'college/university': 'bachelors',\n",
    "    'graduated from space camp': 'spacecamp',\n",
    "    'dropped out of space camp': 'spacecamp',\n",
    "    'graduated from med school': 'advanced degree',\n",
    "    'working on space camp': 'spacecamp',\n",
    "    'working on law school': 'advanced degree',\n",
    "    'working on med school': 'advanced degree',\n",
    "    'dropped out of two-year college': 'high-school',\n",
    "    'two-year college': 'associates',\n",
    "    'masters program': 'advanced degree',\n",
    "    'dropped out of masters program': 'advanced degree',\n",
    "    'dropped out of ph.d program': 'advanced degree',\n",
    "    'high school': 'high-school',\n",
    "    'dropped out of high school': 'high-school',\n",
    "    'working on high school': 'high-school',\n",
    "    'space camp': 'spacecamp',\n",
    "    'ph.d program': 'advanced degree',\n",
    "    'med school': 'advanced degree',\n",
    "    'law school': 'advanced degree',\n",
    "    'dropped out of law school': 'advanced degree',\n",
    "    'dropped out of med school': 'advanced degree',\n",
    "    'graduated from masters program': 'advanced degree'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.replace(label_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bachelors          1059\n",
       "advanced degree     501\n",
       "associates           84\n",
       "high-school          77\n",
       "spacecamp            61\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have consolidated our education labels, we can move on to our dataset, where we will need to fill in missing values and consolidate the range of values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            1782\n",
       "body_type      1635\n",
       "drinks         1727\n",
       "drugs          1392\n",
       "ethnicity      1627\n",
       "height         1782\n",
       "job            1609\n",
       "orientation    1782\n",
       "pets           1230\n",
       "religion       1243\n",
       "sex            1782\n",
       "smokes         1645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns for age, sex, and orientation are all full, so we won't need to fill in missing values, but we will still check the values and do the mappings. We start with the age column, and upon inspection it appears to be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    116\n",
       "28    114\n",
       "27    102\n",
       "25    102\n",
       "26    101\n",
       "30     99\n",
       "31     87\n",
       "32     85\n",
       "24     83\n",
       "23     79\n",
       "33     71\n",
       "35     54\n",
       "22     53\n",
       "34     50\n",
       "37     50\n",
       "36     47\n",
       "21     40\n",
       "42     39\n",
       "38     38\n",
       "20     34\n",
       "41     31\n",
       "43     28\n",
       "40     25\n",
       "47     19\n",
       "46     18\n",
       "39     18\n",
       "45     16\n",
       "44     16\n",
       "48     16\n",
       "19     15\n",
       "52     13\n",
       "51     12\n",
       "18     11\n",
       "50     11\n",
       "55     11\n",
       "49     10\n",
       "56      9\n",
       "60      8\n",
       "59      7\n",
       "62      6\n",
       "54      6\n",
       "61      6\n",
       "58      5\n",
       "68      4\n",
       "57      4\n",
       "53      3\n",
       "63      3\n",
       "67      3\n",
       "65      2\n",
       "64      1\n",
       "66      1\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the unique values in the 'body_type' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average           428\n",
       "fit               377\n",
       "athletic          367\n",
       "thin              147\n",
       "curvy             115\n",
       "a little extra     73\n",
       "skinny             51\n",
       "full figured       38\n",
       "jacked             16\n",
       "overweight         13\n",
       "used up             6\n",
       "rather not say      4\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 6% of the elements are missing a value for body_type. Given that 'average' is the mode of all the values and that it is safe to assume that the typical person have an \"average\" body type, we will fill the NaNs with 'average'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "athletic       760\n",
       "average        579\n",
       "overweight     245\n",
       "underweight    198\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate the values for the body_type column because a lot of them are redundant\n",
    "body_type_dictionary = {\n",
    "    'average': 'average',\n",
    "    'athletic': 'athletic',\n",
    "    'fit': 'athletic',\n",
    "    'thin': 'underweight',\n",
    "    'curvy': 'overweight',\n",
    "    'a little extra': 'overweight',\n",
    "    'skinny': 'underweight',\n",
    "    'full figured': 'overweight',\n",
    "    'jacked': 'athletic',\n",
    "    'overweight': 'overweight',\n",
    "    'used up': 'overweight',\n",
    "    'rather not say': 'average'\n",
    "}\n",
    "\n",
    "data['body_type'] = data['body_type'].fillna('average')\n",
    "data['body_type'] = data['body_type'].replace(body_type_dictionary)\n",
    "data['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'drinks' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "socially       1239\n",
       "rarely          194\n",
       "often           176\n",
       "not at all       90\n",
       "desperately      15\n",
       "very often       13\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical, we can't take an average. Instead, we check the mode, which in this column is \"socially\". The mode makes up about 70% of the total values in this column, so we will fill all NaNs with \"socially.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sometimes     1294\n",
       "rarely         194\n",
       "often          176\n",
       "never           90\n",
       "very often      28\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate the values for the drinks column because a lot of them are redundant\n",
    "drinks_dictionary = {\n",
    "    'socially': 'sometimes',\n",
    "    'often': 'often',\n",
    "    'rarely': 'rarely',\n",
    "    'not at all': 'never',\n",
    "    'desperately': 'very often',\n",
    "    'very often': 'very often'\n",
    "}\n",
    "\n",
    "data['drinks'] = data['drinks'].fillna('socially')\n",
    "data['drinks'] = data['drinks'].replace(drinks_dictionary)\n",
    "data['drinks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'drugs' column and fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        1134\n",
       "sometimes     240\n",
       "often          18\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical once again, we will use the mode, which is \"never\" for this column. It makes up for about 80% of reported values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        1524\n",
       "sometimes     240\n",
       "often          18\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['drugs'] = data['drugs'].fillna('never')\n",
    "data['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'ethnicity' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                                                                                                      1013\n",
       "asian                                                                                                       163\n",
       "hispanic / latin                                                                                             69\n",
       "black                                                                                                        61\n",
       "other                                                                                                        48\n",
       "hispanic / latin, white                                                                                      42\n",
       "indian                                                                                                       38\n",
       "asian, white                                                                                                 26\n",
       "white, other                                                                                                 21\n",
       "asian, pacific islander                                                                                      14\n",
       "middle eastern                                                                                               13\n",
       "black, white                                                                                                 11\n",
       "native american, white                                                                                       10\n",
       "black, other                                                                                                 10\n",
       "middle eastern, white                                                                                         9\n",
       "hispanic / latin, other                                                                                       8\n",
       "black, native american, white                                                                                 7\n",
       "pacific islander                                                                                              6\n",
       "asian, other                                                                                                  5\n",
       "hispanic / latin, white, other                                                                                4\n",
       "middle eastern, hispanic / latin                                                                              4\n",
       "pacific islander, white                                                                                       4\n",
       "native american                                                                                               4\n",
       "black, hispanic / latin                                                                                       3\n",
       "black, white, other                                                                                           2\n",
       "asian, pacific islander, white                                                                                2\n",
       "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other       2\n",
       "asian, pacific islander, hispanic / latin, white, other                                                       2\n",
       "black, hispanic / latin, white                                                                                2\n",
       "asian, white, other                                                                                           2\n",
       "asian, pacific islander, hispanic / latin                                                                     1\n",
       "asian, native american, white, other                                                                          1\n",
       "asian, hispanic / latin                                                                                       1\n",
       "indian, other                                                                                                 1\n",
       "middle eastern, indian, other                                                                                 1\n",
       "native american, pacific islander, hispanic / latin, white, other                                             1\n",
       "middle eastern, other                                                                                         1\n",
       "asian, hispanic / latin, white                                                                                1\n",
       "native american, white, other                                                                                 1\n",
       "indian, hispanic / latin                                                                                      1\n",
       "pacific islander, other                                                                                       1\n",
       "asian, black, pacific islander, hispanic / latin, white                                                       1\n",
       "indian, white, other                                                                                          1\n",
       "pacific islander, white, other                                                                                1\n",
       "black, indian, white, other                                                                                   1\n",
       "native american, pacific islander                                                                             1\n",
       "asian, middle eastern, black, indian, pacific islander, hispanic / latin, white                               1\n",
       "asian, black                                                                                                  1\n",
       "native american, hispanic / latin                                                                             1\n",
       "black, native american, white, other                                                                          1\n",
       "pacific islander, hispanic / latin, white                                                                     1\n",
       "native american, other                                                                                        1\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for ethnicity and fill in missing values\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must again use the mode to fill in missing values for this categorical feature, which ends up being \"white\", making up about 50% of the total data. There was a lot of diversity in ethnicity, so we narrowed down the categories to white, asian, black, hispanic, native, pacific, mixed, and other. If only the second ethnicity is 'other', that means it might be insignificant enough to be ignored, and the row gets classified as the first ethnicity reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white       1189\n",
       "asian        221\n",
       "mixed        164\n",
       "hispanic      77\n",
       "black         71\n",
       "other         48\n",
       "pacific        7\n",
       "native         5\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_dictionary = {\n",
    "    'white': 'white',\n",
    "    'asian': 'asian',\n",
    "    'hispanic / latin': 'hispanic',\n",
    "    'black': 'black',\n",
    "    'other': 'other',\n",
    "    'hispanic / latin, white': 'mixed',\n",
    "    'indian': 'asian',\n",
    "    'asian, white': 'mixed',\n",
    "    'white, other': 'white',\n",
    "    'asian, pacific islander': 'mixed',\n",
    "    'middle eastern': 'asian',\n",
    "    'black, white': 'mixed',\n",
    "    'native american, white': 'mixed',\n",
    "    'black, other': 'black',\n",
    "    'middle eastern, white': 'mixed',\n",
    "    'hispanic / latin, other': 'hispanic',\n",
    "    'black, native american, white': 'mixed',\n",
    "    'pacific islander': 'pacific',\n",
    "    'asian, other': 'asian',\n",
    "    'pacific islander, white': 'mixed',\n",
    "    'native american': 'native',\n",
    "    'middle eastern, hispanic / latin': 'mixed',\n",
    "    'hispanic / latin, white, other': 'mixed',\n",
    "    'black, hispanic / latin': 'mixed',\n",
    "    'asian, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'black, hispanic / latin, white': 'mixed',\n",
    "    'asian, white, other': 'mixed',\n",
    "    'asian, pacific islander, white': 'mixed',\n",
    "    'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'black, white, other': 'mixed',\n",
    "    'indian, other': 'asian',\n",
    "    'indian, white, other': 'mixed',\n",
    "    'black, indian, white, other': 'mixed',\n",
    "    'native american, other': 'native',\n",
    "    'asian, native american, white, other': 'mixed',\n",
    "    'native american, white, other': 'mixed',\n",
    "    'asian, hispanic / latin': 'mixed',\n",
    "    'asian, hispanic / latin, white': 'mixed',\n",
    "    'native american, hispanic / latin': 'mixed',\n",
    "    'native american, pacific islander': 'mixed',\n",
    "    'pacific islander, white, other': 'mixed',\n",
    "    'middle eastern, indian, other': 'mixed',\n",
    "    'pacific islander, other': 'pacific',\n",
    "    'middle eastern, other': 'asian',\n",
    "    'asian, pacific islander, hispanic / latin': 'mixed',\n",
    "    'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'asian, black, pacific islander, hispanic / latin, white': 'mixed',\n",
    "    'black, native american, white, other': 'mixed',\n",
    "    'native american, pacific islander, hispanic / latin, white, other': 'mixed',\n",
    "    'indian, hispanic / latin': 'mixed',\n",
    "    'asian, black': 'mixed'\n",
    "}\n",
    "\n",
    "data['ethnicity'] = data['ethnicity'].fillna('white')\n",
    "data['ethnicity'] = data['ethnicity'].replace(ethnicity_dictionary)\n",
    "data['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'height' column, we decide to fill in missing values using the average height of the row's respective gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['height'] = df['height'].fillna(df.groupby('sex')['height'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'jobs' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                217\n",
       "student                              159\n",
       "science / tech / engineering         158\n",
       "computer / hardware / software       153\n",
       "artistic / musical / writer          136\n",
       "sales / marketing / biz dev          127\n",
       "education / academia                 117\n",
       "medicine / health                     93\n",
       "entertainment / media                 89\n",
       "banking / financial / real estate     80\n",
       "executive / management                67\n",
       "hospitality / travel                  40\n",
       "law / legal services                  35\n",
       "clerical / administrative             31\n",
       "political / government                27\n",
       "construction / craftsmanship          26\n",
       "transportation                        14\n",
       "rather not say                        14\n",
       "unemployed                            10\n",
       "retired                                9\n",
       "military                               7\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values are categorical, and quite a few people already did not want to reveal their job anyways, the empty fields are also clumped into the 'rather not say' category. We narrowed down the categories to student, STEM, arts, business, education, military, not working, and military because there were a lot of different jobs and a lot of them fall into the same category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STEM           444\n",
       "other          404\n",
       "business       345\n",
       "arts           287\n",
       "student        159\n",
       "education      117\n",
       "not working     19\n",
       "military         7\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dictionary = {\n",
    "    'other': 'other',\n",
    "    'student': 'student',\n",
    "    'science / tech / engineering': 'STEM',\n",
    "    'computer / hardware / software': 'STEM',\n",
    "    'artistic / musical / writer': 'arts',\n",
    "    'sales / marketing / biz dev': 'business',\n",
    "    'education / academia': 'education',\n",
    "    'medicine / health': 'STEM',\n",
    "    'banking / financial / real estate': 'business',\n",
    "    'executive / management': 'business',\n",
    "    'hospitality / travel': 'business',\n",
    "    'entertainment / media': 'arts',\n",
    "    'law / legal services': 'arts',\n",
    "    'clerical / administrative': 'business',\n",
    "    'political / government': 'arts', \n",
    "    'construction / craftsmanship': 'STEM',\n",
    "    'rather not say': 'other',\n",
    "    'transportation': 'STEM',\n",
    "    'unemployed': 'not working',\n",
    "    'retired': 'not working',\n",
    "    'military': 'military'\n",
    "}\n",
    "\n",
    "data['job'] = data['job'].fillna('rather not say')\n",
    "data['job'] = data['job'].replace(job_dictionary)\n",
    "data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'pets' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes dogs and likes cats          455\n",
       "likes dogs                         190\n",
       "likes dogs and has cats            155\n",
       "has dogs                           137\n",
       "has dogs and likes cats             80\n",
       "likes dogs and dislikes cats        63\n",
       "has cats                            49\n",
       "has dogs and has cats               47\n",
       "likes cats                          27\n",
       "dislikes dogs and dislikes cats     10\n",
       "has dogs and dislikes cats           9\n",
       "dislikes dogs and likes cats         4\n",
       "dislikes cats                        3\n",
       "dislikes dogs and has cats           1\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of different combinations of liking, disliking or owning dogs or cats, so we narrowed it down to simply pets rather than dogs or cats. We also fill in NaNs with 'likes' as the average person does not mind pets (but we do not want to assume ownership)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes       1291\n",
       "owns         478\n",
       "dislikes      13\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_dictionary = {\n",
    "    'likes dogs and likes cats': 'likes',\n",
    "    'likes dogs': 'likes',\n",
    "    'likes dogs and has cats': 'owns',\n",
    "    'has dogs': 'owns',\n",
    "    'has dogs and likes cats': 'owns',\n",
    "    'likes dogs and dislikes cats': 'likes',\n",
    "    'has cats': 'owns',\n",
    "    'has dogs and has cats': 'owns',\n",
    "    'likes cats': 'likes',\n",
    "    'dislikes dogs and dislikes cats': 'dislikes',\n",
    "    'has dogs and dislikes cats': 'owns',\n",
    "    'dislikes dogs and likes cats': 'likes',\n",
    "    'dislikes cats': 'dislikes',\n",
    "    'dislikes dogs and has cats': 'owns'\n",
    "}\n",
    "\n",
    "data['pets'] = data['pets'].fillna('likes')\n",
    "data['pets'] = data['pets'].replace(pet_dictionary)\n",
    "data['pets'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the 'religion' column for unique values and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agnosticism but not too serious about it      97\n",
       "agnosticism                                   86\n",
       "agnosticism and laughing about it             80\n",
       "other                                         77\n",
       "atheism                                       65\n",
       "other and laughing about it                   63\n",
       "catholicism but not too serious about it      62\n",
       "christianity                                  62\n",
       "atheism and laughing about it                 58\n",
       "christianity but not too serious about it     56\n",
       "atheism but not too serious about it          50\n",
       "other but not too serious about it            47\n",
       "judaism but not too serious about it          45\n",
       "catholicism                                   38\n",
       "other and somewhat serious about it           30\n",
       "catholicism and laughing about it             29\n",
       "atheism and somewhat serious about it         26\n",
       "christianity and somewhat serious about it    26\n",
       "buddhism and laughing about it                23\n",
       "agnosticism and somewhat serious about it     21\n",
       "judaism and laughing about it                 19\n",
       "judaism                                       18\n",
       "atheism and very serious about it             17\n",
       "catholicism and somewhat serious about it     16\n",
       "buddhism but not too serious about it         16\n",
       "christianity and very serious about it        15\n",
       "buddhism                                      15\n",
       "other and very serious about it               14\n",
       "christianity and laughing about it            13\n",
       "agnosticism and very serious about it         12\n",
       "buddhism and somewhat serious about it         8\n",
       "hinduism but not too serious about it          7\n",
       "judaism and somewhat serious about it          6\n",
       "catholicism and very serious about it          6\n",
       "buddhism and very serious about it             4\n",
       "hinduism and somewhat serious about it         4\n",
       "islam                                          3\n",
       "hinduism                                       3\n",
       "islam but not too serious about it             2\n",
       "islam and very serious about it                2\n",
       "hinduism and laughing about it                 1\n",
       "islam and somewhat serious about it            1\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not-listed    770\n",
       "christian     323\n",
       "agnostic      296\n",
       "atheist       216\n",
       "jewish         88\n",
       "buddhist       66\n",
       "hindu          15\n",
       "muslim          8\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to consolidate values for the religion column because there were a lot of redundant values\n",
    "religion_dictionary = {    \n",
    "    \"agnosticism but not too serious about it\": \"agnostic\",\n",
    "    \"agnosticism\": \"agnostic\",\n",
    "    \"agnosticism and laughing about it\": \"agnostic\",\n",
    "    \"other\": \"not-listed\",\n",
    "    \"atheism\": \"atheist\",\n",
    "    \"other and laughing about it\": \"not-listed\",\n",
    "    \"christianity\": \"christian\",\n",
    "    \"catholicism but not too serious about it\": \"christian\",\n",
    "    \"atheism and laughing about it\": \"atheist\",\n",
    "    \"christianity but not too serious about it\": \"christian\",\n",
    "    \"atheism but not too serious about it\": \"atheist\",\n",
    "    \"other but not too serious about it\": \"not-listed\",\n",
    "    \"judaism but not too serious about it\": \"jewish\",\n",
    "    \"catholicism\": \"christian\",\n",
    "    \"other and somewhat serious about it\": \"not-listed\",\n",
    "    \"catholicism and laughing about it\": \"christian\",\n",
    "    \"christianity and somewhat serious about it\": \"christian\",\n",
    "    \"atheism and somewhat serious about it\": \"atheist\",\n",
    "    \"buddhism and laughing about it\": \"buddhist\",\n",
    "    \"agnosticism and somewhat serious about it\": \"agnostic\",\n",
    "    \"judaism and laughing about it\": \"jewish\",\n",
    "    \"judaism\": \"jewish\",\n",
    "    \"atheism and very serious about it\": \"atheist\",\n",
    "    \"catholicism and somewhat serious about it\": \"christian\",\n",
    "    \"buddhism but not too serious about it\": \"buddhist\",\n",
    "    \"buddhism\": \"buddhist\",\n",
    "    \"christianity and very serious about it\": \"christian\",\n",
    "    \"other and very serious about it\": \"not-listed\",\n",
    "    \"christianity and laughing about it\": \"christian\",\n",
    "    \"agnosticism and very serious about it\": \"agnostic\",\n",
    "    \"buddhism and somewhat serious about it\": \"buddhist\",\n",
    "    \"hinduism but not too serious about it\": \"hindu\",\n",
    "    \"judaism and somewhat serious about it\": \"jewish\",\n",
    "    \"catholicism and very serious about it\": \"christian\",\n",
    "    \"hinduism and somewhat serious about it\": \"hindu\",\n",
    "    \"buddhism and very serious about it\": \"buddhist\",\n",
    "    \"hinduism\": \"hindu\",\n",
    "    \"islam\": \"muslim\",\n",
    "    \"islam but not too serious about it\": \"muslim\",\n",
    "    \"islam and very serious about it\": \"muslim\",\n",
    "    \"hinduism and laughing about it\": \"hindu\",\n",
    "    \"islam and somewhat serious about it\": \"muslim\",\n",
    "    \"hinduism and very serious about it\": \"hindu\",\n",
    "    \"judaism and very serious about it\": \"jewish\",\n",
    "    \"islam and laughing about it\": \"muslim\"\n",
    "}\n",
    "\n",
    "data['religion'] = data['religion'].fillna('not-listed')\n",
    "data['religion'] = data['religion'].replace(religion_dictionary)\n",
    "data['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check unique values for the 'smokes' column and fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                1352\n",
       "sometimes          110\n",
       "when drinking       83\n",
       "yes                 55\n",
       "trying to quit      45\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will check unique values for smokes and fill in missing values\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mode for this column is 'no', making up about 75% of the data. We accordingly fill in Nans with 'no'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                1489\n",
       "sometimes          110\n",
       "when drinking       83\n",
       "yes                 55\n",
       "trying to quit      45\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'no' is the mode and makes up about 75% of the data, so we will fill NaNs with 'no'\n",
    "data['smokes'] = data['smokes'].fillna('no')\n",
    "data['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We can convert some of the categorical features into numerical values because they are on a ordinal scale. This allows there to be a larger difference between values that are further away. For example, in the drinks column, 'often' is further from 'never' than 'sometimes' is. This conversion to numerical values for ordinal features allows us to visualize this magnitude in difference rather than having the standard distance of 1 between different categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>job</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>asian</td>\n",
       "      <td>65.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>straight</td>\n",
       "      <td>2</td>\n",
       "      <td>christian</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>63.0</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "      <td>2</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>arts</td>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mixed</td>\n",
       "      <td>68.0</td>\n",
       "      <td>education</td>\n",
       "      <td>gay</td>\n",
       "      <td>1</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>63.0</td>\n",
       "      <td>education</td>\n",
       "      <td>straight</td>\n",
       "      <td>1</td>\n",
       "      <td>not-listed</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  body_type  drinks  drugs ethnicity  height        job orientation  \\\n",
       "0   28          2       2      1     asian    65.0       STEM    straight   \n",
       "1   34          1       2      0     white    63.0      other    straight   \n",
       "2   29          2       2      0     white    70.0       arts    straight   \n",
       "3   45          2       0      0     mixed    68.0  education         gay   \n",
       "4   37          1       2      0     white    63.0  education    straight   \n",
       "\n",
       "   pets    religion sex  smokes  \n",
       "0     2   christian   m       0  \n",
       "1     2  not-listed   f       0  \n",
       "2     1  not-listed   m       0  \n",
       "3     1  not-listed   m       0  \n",
       "4     1  not-listed   f       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts some of the categorical features into values because they are ordinal\n",
    "def convert_ordinal(data):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    drugs_codes = {\n",
    "        'never': 0,\n",
    "        'sometimes': 1,\n",
    "        'often': 2\n",
    "    }\n",
    "\n",
    "    drinks_codes = {\n",
    "        'never': 0,\n",
    "        'rarely': 1,\n",
    "        'sometimes': 2,\n",
    "        'often': 3,\n",
    "        'very often': 4\n",
    "    }\n",
    "\n",
    "    smokes_codes = {\n",
    "        \"no\": 0,\n",
    "        \"when drinking\": 1,\n",
    "        \"trying to quit\": 2,\n",
    "        \"sometimes\": 3,\n",
    "        \"yes\": 4\n",
    "    }\n",
    "\n",
    "    pets_codes = {\n",
    "        \"dislikes\": 0,\n",
    "        \"likes\": 1,\n",
    "        \"owns\": 2\n",
    "    }\n",
    "    \n",
    "    body_codes = {\n",
    "        \"underweight\": 0,\n",
    "        \"average\": 1,\n",
    "        \"athletic\": 2,\n",
    "        \"overweight\": 3\n",
    "    }\n",
    "\n",
    "    copy['drugs'] = data['drugs'].replace(drugs_codes)\n",
    "    copy['drinks'] = data['drinks'].replace(drinks_codes)\n",
    "    copy['smokes'] = data['smokes'].replace(smokes_codes)\n",
    "    copy['pets'] = data['pets'].replace(pets_codes)\n",
    "    copy['body_type'] = data['body_type'].replace(body_codes)\n",
    "    return copy\n",
    "\n",
    "data = convert_ordinal(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models that we plan on using do not accept categorical data. Therefore, for the categorical features that weren't ordinal, we had to use one-hot encoding to be able to use the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>pets</th>\n",
       "      <th>smokes</th>\n",
       "      <th>ethnicity_asian</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>religion_agnostic</th>\n",
       "      <th>religion_atheist</th>\n",
       "      <th>religion_buddhist</th>\n",
       "      <th>religion_christian</th>\n",
       "      <th>religion_hindu</th>\n",
       "      <th>religion_jewish</th>\n",
       "      <th>religion_muslim</th>\n",
       "      <th>religion_not-listed</th>\n",
       "      <th>sex_f</th>\n",
       "      <th>sex_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  body_type  drinks  drugs  height  pets  smokes  ethnicity_asian  \\\n",
       "0   28          2       2      1    65.0     2       0                1   \n",
       "1   34          1       2      0    63.0     2       0                0   \n",
       "2   29          2       2      0    70.0     1       0                0   \n",
       "3   45          2       0      0    68.0     1       0                0   \n",
       "4   37          1       2      0    63.0     1       0                0   \n",
       "\n",
       "   ethnicity_black  ethnicity_hispanic  ...    religion_agnostic  \\\n",
       "0                0                   0  ...                    0   \n",
       "1                0                   0  ...                    0   \n",
       "2                0                   0  ...                    0   \n",
       "3                0                   0  ...                    0   \n",
       "4                0                   0  ...                    0   \n",
       "\n",
       "   religion_atheist  religion_buddhist  religion_christian  religion_hindu  \\\n",
       "0                 0                  0                   1               0   \n",
       "1                 0                  0                   0               0   \n",
       "2                 0                  0                   0               0   \n",
       "3                 0                  0                   0               0   \n",
       "4                 0                  0                   0               0   \n",
       "\n",
       "   religion_jewish  religion_muslim  religion_not-listed  sex_f  sex_m  \n",
       "0                0                0                    0      0      1  \n",
       "1                0                0                    1      1      0  \n",
       "2                0                0                    1      0      1  \n",
       "3                0                0                    1      0      1  \n",
       "4                0                0                    1      1      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding categorical features that are not ordinal\n",
    "def one_hot_encode(data, column=None):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    if column is None:\n",
    "        to_encode = ['ethnicity', 'job', 'orientation', 'religion', 'sex']\n",
    "        for column in to_encode:\n",
    "            copy = one_hot_encode(copy, column)\n",
    "    else:\n",
    "        dummies = pd.get_dummies(copy[[column]])\n",
    "        copy = pd.concat([copy, dummies], axis=1)\n",
    "        copy = copy.drop([column], axis=1)\n",
    "        \n",
    "    return copy\n",
    "\n",
    "one_hot_encode(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the models that we plan on using are very sensitive to the effect of outliers, so we have to remove them in order for the models to function effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  body_type  drinks  drugs ethnicity  height        job orientation  \\\n",
      "0   28          2       2      1     asian    65.0       STEM    straight   \n",
      "1   34          1       2      0     white    63.0      other    straight   \n",
      "2   29          2       2      0     white    70.0       arts    straight   \n",
      "3   45          2       0      0     mixed    68.0  education         gay   \n",
      "4   37          1       2      0     white    63.0  education    straight   \n",
      "\n",
      "   pets    religion sex  smokes  \n",
      "0     2   christian   m       0  \n",
      "1     2  not-listed   f       0  \n",
      "2     1  not-listed   m       0  \n",
      "3     1  not-listed   m       0  \n",
      "4     1  not-listed   f       0  \n",
      "0    advanced degree\n",
      "1    advanced degree\n",
      "2          bachelors\n",
      "3          bachelors\n",
      "4    advanced degree\n",
      "Name: education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removes outliers from the data using isolation forests\n",
    "def remove_outliers(data, labels):\n",
    "    data_cp = data.copy()\n",
    "    labels_cp = labels.copy()\n",
    "    \n",
    "    iso_forest = ensemble.IsolationForest(n_estimators=100, contamination=0.05)\n",
    "    pred = iso_forest.fit_predict(data_cp.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex']))\n",
    "    pred = pd.Series(pred)\n",
    "    data_cp = data_cp[pred == 1].reset_index(drop=True)\n",
    "    labels_cp = labels_cp[pred == 1].reset_index(drop=True)\n",
    "    \n",
    "    return (data_cp, labels_cp)\n",
    "\n",
    "data_cp, labels_cp = remove_outliers(data, label)\n",
    "print(data_cp.head())\n",
    "print(labels_cp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to try balanced data due to there being too many or too few of a certain value in a column. We upsample and downsample accordingly in an attempt to even out any class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  body_type  drinks  drugs ethnicity  height       job orientation  \\\n",
      "0   24          2       2      1     other    63.0     other         gay   \n",
      "1   22          0       2      1     white    63.0     other         gay   \n",
      "2   51          3       2      0     mixed    67.0      arts    straight   \n",
      "3   27          2       2      0     white    71.0  business    straight   \n",
      "4   36          2       2      0     white    70.0      STEM    straight   \n",
      "\n",
      "   pets    religion sex  smokes  \n",
      "0     1  not-listed   f       0  \n",
      "1     2  not-listed   f       3  \n",
      "2     1  not-listed   f       0  \n",
      "3     1  not-listed   f       0  \n",
      "4     1  not-listed   m       0  \n",
      "0          spacecamp\n",
      "1          bachelors\n",
      "2          spacecamp\n",
      "3          bachelors\n",
      "4    advanced degree\n",
      "Name: education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# balancing the data \n",
    "def balance_data(data, labels, rows=400):\n",
    "    all_data = pd.concat([data, labels], axis=1)\n",
    "    unique_labels = labels.unique()\n",
    "    \n",
    "    to_concat = []\n",
    "    for label in unique_labels:\n",
    "        num_label = len(all_data[all_data['education']==label].index)\n",
    "        if num_label > rows:\n",
    "            #downsample\n",
    "            down = all_data[all_data['education']==label].sample(n=rows)\n",
    "            to_concat.append(down)\n",
    "        elif num_label < rows:\n",
    "            #upsample\n",
    "            choices = all_data[all_data['education']==label]\n",
    "            indices = np.array(choices.index)\n",
    "            resampled_indices = np.random.choice(indices, size=rows, replace=True)\n",
    "            up = choices.loc[resampled_indices]\n",
    "            to_concat.append(up)\n",
    "    \n",
    "    new_df = pd.concat(to_concat, axis=0).sample(frac=1).reset_index(drop=True)\n",
    "    new_labels = new_df['education']\n",
    "    new_data = new_df.drop(columns=['education'])\n",
    "    \n",
    "    return new_data, new_labels\n",
    "\n",
    "data_balanced, labels_balanced = balance_data(data, label)\n",
    "print(data_balanced.head())\n",
    "print(labels_balanced.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "The first model we tried was a KNN classifier. It's a common classifier and we decided to start out seeing what accuracy we could get with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.5651774309945504\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "knn_data = one_hot_encode(data)\n",
    "\n",
    "param_grid = {'pca__n_components': [val / 20 for val in range(12, 20)], 'knn__n_neighbors': list(range(5, 10))}\n",
    "inner = model_selection.GridSearchCV(ppl, param_grid, scoring='f1_micro', cv=5, iid=True)\n",
    "scores = model_selection.cross_val_score(inner, knn_data, label, cv=5)\n",
    "print('F1-score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding optimal parameters and doing cross validation, the accuracy of KNN was not too high. Unfortunately, we couldn't print the best hyperparameters such as knn__n_neighbors as they differ per iteration of the outer loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "We decided to try a decision tree next, as they typically work well with categorical data that can be split along the unique values and does not break down in high dimensionality, which is a benefit for us as we have a large number of columns because of the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5936837143980884\n"
     ]
    }
   ],
   "source": [
    "tree_data = one_hot_encode(data)\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'min_samples_leaf': [val / 200 for val in range(1, 11)]}\n",
    "inner = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "scores = model_selection.cross_val_score(inner, tree_data, label, cv=5)\n",
    "print('Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree ended up beating out the KNN classifier by about 3% in accuracy. This isn't as sizeable an increase in accuracy as we would have hoped, but it is still an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMs\n",
    "\n",
    "Since we had labeled data, we also wanted to try an SVM, which is a supervised learning model. For comparison's sake, we also tried out an SVC, which does not use the labels for training. We also compared the performance of unbalanced to balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs One accuracy: 0.3938828221292119\n",
      "One vs Rest accuracy: 0.42421893723631987\n"
     ]
    }
   ],
   "source": [
    "def run_svm_model(data, labels, outer_model, name):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('clf', outer_model)])\n",
    "    \n",
    "    svm_data = one_hot_encode(data)\n",
    "\n",
    "    inner_clfs = [svm.SVC(kernel=type, class_weight='balanced') for type in ['linear', 'poly', 'sigmoid', 'rbf']]\n",
    "    inner_clfs.extend([svm.LinearSVC(loss=type, class_weight='balanced') for type in ['hinge', 'squared_hinge']])\n",
    "    param_grid = {'pca__n_components': [val / 10 for val in range(6, 10)], 'clf__estimator': inner_clfs}\n",
    "    \n",
    "    inner = model_selection.GridSearchCV(ppl, param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "    scores = model_selection.cross_val_score(inner, svm_data, labels, cv=5)\n",
    "    print(name, 'accuracy:', scores.mean())\n",
    "\n",
    "run_svm_model(data, label, multiclass.OneVsOneClassifier(None), 'One vs One')\n",
    "run_svm_model(data, label, multiclass.OneVsRestClassifier(None), 'One vs Rest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced SVM accuracy 0.46575822496666425\n",
      "Unbalanced SVM F1-score 0.585315913487519\n"
     ]
    }
   ],
   "source": [
    "def run_svc_model(data, labels, balanced):\n",
    "    weight = 'balanced' if balanced else None\n",
    "    score = 'accuracy' if balanced else 'f1_micro'\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    svc = svm.SVC(class_weight=weight)\n",
    "    ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('pca', pca), ('svm', svc)])\n",
    "\n",
    "    svm_data = one_hot_encode(data)\n",
    "\n",
    "    kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "    costs = [1.0, 10.0, 100.0]\n",
    "    param_grid = {'svm__kernel': kernels, 'svm__C': costs, 'svm__decision_function_shape': ['ovo', 'ovr']}\n",
    "\n",
    "    inner = model_selection.GridSearchCV(ppl, param_grid, scoring=score, cv=5, iid=True)\n",
    "    scores = model_selection.cross_val_score(inner, svm_data, labels, cv=5)\n",
    "    \n",
    "    if balanced:\n",
    "        print('Balanced SVM accuracy', scores.mean())\n",
    "    else:\n",
    "        print('Unbalanced SVM F1-score', scores.mean())\n",
    "\n",
    "run_svc_model(data, label, True)\n",
    "run_svc_model(data, label, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the SVM accuracy on balanced data was significantly lower than on unbalanced data. Balancing the data upsampled or downsampled data from certain classes based on the parameter. Given the heavy class imbalance favoring bachelors, it makes sense why a balanced SVM that used data that downsampled bachelors data and upsampled data from other classes would have a lower accuracy as now it could be overfitting to elements from underrepresented classes, causing those to be predicted more. \n",
    "\n",
    "The unbalanced SVM had a comparable, but slightly lower accuracy then our best performing models, such as NNs and Decision Trees. However, the downside of the SVM was that it took very long to run. It took about 2 to 3 hours to run on our small, test dataset. Given the speed required and large datasets used (as this dataset is only data from California) by modern data scientists, we would advise against using an SVM. Everytime you tweak a parameter, it takes a long time to rerun and evaluate. We believe that the time to run is so long as it is difficult to find a hyperplane through the data given that our data has so many dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "We also wanted to try a naive bayes model. Since we don't know the distribution of the data, I tried both GaussianNB and MultinomialNB. The model accuracy was extremely poor with one hot encoding, so I had to remove the categorical features that were ordinal. I used 10 fold cross-validation, and got an F1-score of around 54% for both GaussianNB, and MultinomialNB, with MultinomialNB having the slightly higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes using GaussianNB\n",
      "10 Fold Cross Validation F1-score: 0.5325069477409279 \n",
      "\n",
      "Naive Bayes using MultinomialNB\n",
      "10 Fold Cross Validation F1-score: 0.5477295899201874 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_naive_bayes(data, labels, isGaussianNB):\n",
    "    if isGaussianNB:\n",
    "        classifier = naive_bayes.GaussianNB()\n",
    "        classifier_roc_curve = naive_bayes.GaussianNB()\n",
    "    else:\n",
    "        classifier = naive_bayes.MultinomialNB()\n",
    "        classifier_roc_curve = naive_bayes.MultinomialNB()\n",
    "    bayes_data = data.drop(columns=['ethnicity', 'job', 'orientation', 'religion', 'sex'])\n",
    "    \n",
    "    scores = model_selection.cross_val_score(classifier, bayes_data, labels, scoring='f1_micro', cv=10)\n",
    "    \n",
    "    print('10 Fold Cross Validation F1-score:', str(scores.mean()), '\\n')\n",
    "\n",
    "print('Naive Bayes using GaussianNB')\n",
    "run_naive_bayes(data, label, True)\n",
    "\n",
    "print('Naive Bayes using MultinomialNB')\n",
    "run_naive_bayes(data, label, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB is typically used when the data is typically used when features have a normal distribution and are continuous. In the case of this dataset, the data isn't really continous except for features such as height, so that would explain the relatively lower accuracy, both in terms of comparison to multinomial and to other models.\n",
    "\n",
    "MultinomialNB is typically used with discrete data, which is the case for this dataset, explaining the improved accuracy over gaussian. However, we believe that the accuracy measure, F1-Score, is lower in comparison to other models, because naive bayes takes a probabilistic approach to prediction. We look at how often a feature has a value given a certain class. In the case of our data, when looking at one feature individually, the probability of it occuring given a certain is about equal for each class, making it difficult to create accurate predictions. In easier terms, it is equally as likely that someone is 6 feet tall given that they have an advanced and that someone is 6 feet tall and holds a bachelors degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "Neural networks are often a good option for predictive models, so we decided to try that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5992948303581788\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "nn = neural_network.MLPClassifier()\n",
    "ppl = pipeline.Pipeline(steps=[('scaler', scaler), ('nn', nn)])\n",
    "\n",
    "nn_data, nn_labels = remove_outliers(data, label)\n",
    "# nn_data, nn_labels = balance_data(nn_data, nn_labels)\n",
    "nn_data = one_hot_encode(nn_data)\n",
    "\n",
    "param_grid = {'nn__activation': ['logistic', 'tanh', 'relu'], 'nn__solver': ['sgd', 'adam'], 'nn__learning_rate': ['constant', 'adaptive']}\n",
    "inner = model_selection.GridSearchCV(ppl, param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "scores = model_selection.cross_val_score(inner, nn_data, nn_labels, cv=5)\n",
    "print('Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found an accuracy of about 60%, the best we've seen so far. This beats the accuracy of Decision Trees by a little so we would consider them to be equally as accurate. We believe that NNs worked so well as they weigh features that have importance with a heavier weight value, finding the essential features while diminishing the impact that a less important feature, say religion, may have in prediction education. This is different that a Decision Tree as a Decision Tree splits upon any discrete variable, and while the end leaves may have the same label, there is a possibility that they have different predicted classes. NNs can remove that possibility through providing weights to the deemed 'essential or important' features that are more important in predictions. NNs also had the advantage of not breaking down in higher dimensions, which might have happened in some of the other models because of the large number of columns are in our data, and is exacerbated by the one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "Ensembles made sense to test last, since we now have several different classifiers which we can put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_data, ensemble_labels = remove_outliers(data, label)\n",
    "ensemble_data = one_hot_encode(ensemble_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6022422905752398\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [25,30,35,40], 'min_samples_leaf': [0.002,0.005,0.01], 'max_features': ('sqrt','log2')}\n",
    "inner = model_selection.GridSearchCV(ensemble.RandomForestClassifier(n_estimators=100), param_grid, scoring='accuracy', cv=5)\n",
    "scores = model_selection.cross_val_score(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5797859931670587\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150], 'learning_rate': [0.7, 0.85, 1.0]}\n",
    "inner = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, scoring='accuracy', cv=5)\n",
    "scores = model_selection.cross_val_score(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5809520312459757\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('dt', tree.DecisionTreeClassifier()),\n",
    "    ('nn', pipeline.make_pipeline(preprocessing.MinMaxScaler(), neural_network.MLPClassifier())),\n",
    "    ('svc', pipeline.make_pipeline(preprocessing.StandardScaler(), decomposition.PCA(n_components=7), svm.SVC(decision_function_shape='ovr')))\n",
    "]\n",
    "\n",
    "param_grid = {'weights': [[1, 1, 1], [1, 1, 0.7]]}\n",
    "inner = model_selection.GridSearchCV(ensemble.VotingClassifier(estimators=estimators), param_grid, scoring='accuracy', cv=5, iid=True)\n",
    "scores = model_selection.cross_val_score(inner, ensemble_data, ensemble_labels, cv=5)\n",
    "print('Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the ensemble turned out to be around the average of the ensembled classifiers. This is potentially indicative of the different classifiers overlapping in what classes they predict for certain points. For an ensemble, it would be preferable that the classifiers cover different parts of the data in terms of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The average accuracies were between 57% and 60%. Our data was primarily categorical and had to be scaled \n",
    "using one-hot encoding, which increased our number of columns. By increasing the number of dimensions, our models\n",
    "and predictive algorithms fell to the curse of dimensionality. Additionally, we were attempting to predict one of 5 \n",
    "different labels, which makes it difficult to predict with a high accuracy, especially given that our data was\n",
    "primarily categorical. Given these circumstances, I do believe that our predictive algorithms are accurate.\n",
    "\n",
    "However, there was a heavy class imbalance favoring 'bachelors'. This class made up about 60% of the data. Additionally,\n",
    "using domain knowledge of real life experiences, it seems very difficult to predict someone's education level based\n",
    "on factors such as religion, whether or not they smoke or drink, body type, preference for pets, and height. It is \n",
    "possible for someone of any religion to have any level of education and someone who is tall or short could receive \n",
    "their ph.d. Features such as income and job are far better indicators of education level. The problem we faced with \n",
    "income was that the majority of values were missing, which makes sense as the data is self reported. The problem we \n",
    "faced with job/occupation was that there were a lot of unique values, which would further worsen the curse of\n",
    "dimensionality. Even with the given values, the job values were very vague and didn't give any specific role \n",
    "details that could be used to predict education. For example, there was a value of 'entertainment'. This could include\n",
    "the most succesful singers in the world who make millions of dollars or a local band member who was still in high school.\n",
    "We also found another potential source of error could come from the fact that the data was self reported. This means that\n",
    "if someone was embarrased or thought a factor about themselves, such as body type, was unattractive, they would not \n",
    "report it. This could lead to a lot of significant or differentiating factors to be missing. Since on a dating website, people are\n",
    "encouraged to portray the best version of themselves to make themselves attractive to potential partners. Therefore, there\n",
    "may be inaccuracy is some of the data, especially in features such as height, body type, drinks, and smokes, where people\n",
    "might lie to conceal some of their poorer features, affecting the models that we use.\n",
    "\n",
    "Another aspect that we found to complicate predicting the labels was that one of the classes was 'space camp'. We were \n",
    "not sure why this was an option and is it clearly did not indicate a real or serious education level, but felt that \n",
    "we should not remove the elements that belonged to the 'space camp' class as it was not insignificant. Given that this\n",
    "was a fake class, predicting this class was difficult as there are no real factors that indicate whether someone's\n",
    "education level was space camp. Two elements could have the exact same attributes and one could have a class of \n",
    "'advanced degree' while the other could have a class of 'space camp', which simply complicates the model or algorithm.\n",
    "\n",
    "\n",
    "All in all, while we were able to predict the education level around a 60% accuracy, we cannot conclude that there is \n",
    "necessarily a strong correlation between the features that we explored and education level. Given the slight imbalance\n",
    "favoring 'bachelors', predicting 'bachelors' for every element would result in the same accuracy. However, we did find \n",
    "that our predictions were not just 'bachelors', which was only predicted 60 - 75% of the time. This is a good sign that \n",
    "our models did fit to the data and find some level of correlation between the features and the labels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
